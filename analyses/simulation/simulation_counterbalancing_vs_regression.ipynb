{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation counterbalancing vs. regression\n",
    "To do:\n",
    "- create correlated data (perhaps in separate function?)\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_selection import f_classif\n",
    "from skbold.preproc import ConfoundRegressor, MajorityUndersampler\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "0.496\n"
     ]
    }
   ],
   "source": [
    "iters = 5\n",
    "n_samp = 100\n",
    "n_feat = 5\n",
    "n_fold = 10\n",
    "std = 1\n",
    "\n",
    "skf = StratifiedKFold(n_splits=n_fold)\n",
    "\n",
    "results = {'accuracy': np.zeros(iters)}\n",
    "\n",
    "confound_control = 'regress'\n",
    "acc = np.zeros((iters, n_fold))\n",
    "for i in range(iters):\n",
    "    \n",
    "    if i % int(iters / 5) == 0:\n",
    "        print(\"Iteration %i\" % i)\n",
    "\n",
    "    n_half = int(n_samp / 2)\n",
    "    y = np.repeat([0, 1], repeats=n_half)\n",
    "    c = np.roll(y, 10)\n",
    "    \n",
    "    data = np.random.randn(n_samp, n_feat)\n",
    "    #data[c == 1, :] += 1\n",
    "    data[y == 1, :] += 0.5\n",
    "    X = data\n",
    "    \n",
    "    for ii, (train_idx, test_idx) in enumerate(skf.split(X, y)):\n",
    "        \n",
    "        pipeline = [\n",
    "            ('confoundreg', ConfoundRegressor(confound=y, fit_idx=train_idx, cross_validate=True)),\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('svm', SVC(kernel='linear'))\n",
    "        ]\n",
    "        \n",
    "        if confound_control != 'regress':\n",
    "            pipeline.pop(0)\n",
    "        \n",
    "        pipeline = Pipeline(pipeline)\n",
    "        \n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "        \n",
    "        if confound_control == 'cb':\n",
    "            idx = counterbalance(y_train, c[train_idx], verbose=False)\n",
    "            X_train, y_train = X_train[idx], y_train[idx]\n",
    "            \n",
    "        #print(f_classif(X_train, y_train)[0])\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        acc[i, ii] = pipeline.score(X_test, y_test)\n",
    "    results['accuracy'][i] = acc[i, :].mean()\n",
    "print(np.mean(results['accuracy']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from scipy.stats import itemfreq\n",
    "\n",
    "class CounterbalancedStratifiedSplit(object):\n",
    "    \n",
    "    def __init__(self, X, y, c, counterbalance_tolerance=.05, n_splits=5, verbose=False):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.c = c\n",
    "        self.counterbalance_tolerance = counterbalance_tolerance\n",
    "        self.n_splits = n_splits\n",
    "        self.verbose = verbose\n",
    "\n",
    "        self.subsample_idx = np.arange(len(y))\n",
    "        self.c_classes = np.unique(c)\n",
    "        self.n_confound_classes = len(self.c_classes)\n",
    "        self.counterbalanced_proportion = np.divide(1, self.n_confound_classes)\n",
    "        self.y_classes = np.unique(y)\n",
    "\n",
    "        self.seed = None\n",
    "        self.checked_possible = False\n",
    "    \n",
    "    def check_possible(self):\n",
    "        \"\"\" Check if the confound classes are counterbalanced in each class of y \"\"\"\n",
    "        \n",
    "        if self.verbose:\n",
    "            print('Checking if a counterbalanced split is possible without subsampling...')\n",
    "        \n",
    "        select_idx = np.array([])\n",
    "        for y_class in self.y_classes:\n",
    "            idx = y == y_class\n",
    "            y_sub = y[idx]\n",
    "            \n",
    "            # Get frequency table of all confound classes\n",
    "            freqs = itemfreq(c[idx])\n",
    "            \n",
    "            # Get absolute difference\n",
    "            diffs = freqs[:,1].reshape(-1, 1) - freqs[:,1]\n",
    "            \n",
    "            # If any absolute difference is larger than 0, we have confound imbalance\n",
    "            if np.max(diffs) > 0:\n",
    "                print('Oops! The confound classes are not counterbalanced within y-class %s. Subsampling...' % str(y_class))\n",
    "                \n",
    "                for c_class in self.c_classes:\n",
    "                    # From self.subsample_idx, sample the idx of the number of y-class observations necessary to obtain a balanced class\n",
    "                    select_idx = np.concatenate((select_idx, np.random.choice(self.subsample_idx[(y == y_class) & (c == c_class)], size=np.min(freqs[:,1]), replace=False)))\n",
    "            else:\n",
    "                # If confound classes are counterbalanced within this y_class, select all of these idx\n",
    "                select_idx = np.concatenate((select_idx, self.subsample_idx[idx]))\n",
    "\n",
    "        self.checked_possible = True\n",
    "        self.subsample_idx = np.sort(select_idx).astype(int)\n",
    "        \n",
    "        if self.verbose:\n",
    "            print('After subsampling, proportions of c-classes in y_classes:')\n",
    "            y_tmp = y[self.subsample_idx]\n",
    "            c_tmp = c[self.subsample_idx]\n",
    "\n",
    "            for y_class in self.y_classes:\n",
    "                print(itemfreq(c_tmp[y_tmp == y_class]))\n",
    "\n",
    "    \n",
    "    def find_counterbalanced_seed(self, max_attempts=50000):\n",
    "        \"\"\" Find a seed of Stratified K-Fold that gives counterbalanced classes \"\"\"\n",
    "\n",
    "        if not self.checked_possible:\n",
    "            self.check_possible()\n",
    "        \n",
    "        X_tmp = deepcopy(self.X)[self.subsample_idx]\n",
    "        y_tmp = deepcopy(self.y)[self.subsample_idx]\n",
    "        c_tmp = deepcopy(self.c)[self.subsample_idx]\n",
    "                \n",
    "        for i, sd in enumerate(np.random.randint(low=0, high=1e7, size=max_attempts, dtype=int)):\n",
    "            skf = StratifiedKFold(n_splits=self.n_splits, shuffle=True, random_state=sd)\n",
    "            bad_split = False\n",
    "\n",
    "            for (train_idx, test_idx) in skf.split(X_tmp, y_tmp):\n",
    "                if bad_split:\n",
    "                    if self.verbose and i % 100 == 0:\n",
    "                        print('.', end='')\n",
    "                    break\n",
    "\n",
    "                for set_ in (train_idx, test_idx):\n",
    "                    y_set = y_tmp[set_]\n",
    "                    c_set = c_tmp[set_]\n",
    "                    \n",
    "                    for y_class in self.y_classes:\n",
    "                        y_set_class = y_set[y_set == y_class]\n",
    "                        c_set_class = c_set[y_set == y_class]\n",
    "\n",
    "                        # Get proportions of each class of c for each y_class\n",
    "                        proportions = itemfreq(c_set_class).astype(float)[:,1]/len(c_set_class)\n",
    "\n",
    "                        # Check whether the proportions are equal\n",
    "                        if proportions.shape[0] == 1 or np.max(proportions.reshape(-1,1) - proportions) > self.counterbalance_tolerance:\n",
    "                            bad_split = True\n",
    "\n",
    "            if not bad_split:\n",
    "                if self.verbose:\n",
    "                    print('\\nGood split found! Seed %d was used.' % i)\n",
    "                self.seed = sd\n",
    "                return\n",
    "                \n",
    "        if self.seed is None:\n",
    "            raise(ValueError('\\nSorry, could not find any good split...'))\n",
    "            \n",
    "        \n",
    "    def split(self, X, y):\n",
    "        \"\"\" The final idx to output are subsamples of the subsample_idx... \"\"\"\n",
    "        \n",
    "        if self.seed is None:\n",
    "            raise(IOError('You need to run CounterbalancedStratifiedSplit.find_counterbalanced_seed() first'))\n",
    "        \n",
    "        X_tmp = X[self.subsample_idx]\n",
    "        y_tmp = y[self.subsample_idx]\n",
    "        \n",
    "        skf = StratifiedKFold(n_splits=self.n_splits, shuffle=True, random_state=self.seed)\n",
    "        \n",
    "        for (train_idx, test_idx) in skf.split(X=X_tmp, y=y_tmp):\n",
    "            yield ((self.subsample_idx[train_idx], self.subsample_idx[test_idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the CSS-class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking if a counterbalanced split is possible without subsampling...\n",
      "Oops! The confound classes are not counterbalanced within y-class 0. Subsampling...\n",
      "Oops! The confound classes are not counterbalanced within y-class 1. Subsampling...\n",
      "After subsampling, proportions of c-classes in y_classes:\n",
      "[[ 0 10]\n",
      " [ 1 10]]\n",
      "[[ 0 10]\n",
      " [ 1 10]]\n",
      "[[0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]]\n",
      ".....\n",
      "Good split found! Seed 436 was used.\n",
      "train set, y and confound:\n",
      "    confound  y\n",
      "0          1  0\n",
      "1          1  0\n",
      "2          1  0\n",
      "3          1  0\n",
      "4          1  0\n",
      "5          1  0\n",
      "6          1  0\n",
      "7          1  0\n",
      "8          0  0\n",
      "9          0  0\n",
      "10         0  0\n",
      "11         0  0\n",
      "12         0  0\n",
      "13         0  0\n",
      "14         0  0\n",
      "15         0  0\n",
      "16         0  1\n",
      "17         0  1\n",
      "18         0  1\n",
      "19         0  1\n",
      "20         0  1\n",
      "21         0  1\n",
      "22         0  1\n",
      "23         0  1\n",
      "24         1  1\n",
      "25         1  1\n",
      "26         1  1\n",
      "27         1  1\n",
      "28         1  1\n",
      "29         1  1\n",
      "30         1  1\n",
      "31         1  1\n",
      "\n",
      "train set confound count per class: \n",
      "[[ 0 16]\n",
      " [ 1 16]]\n",
      "test set, y and confound:\n",
      "   confound  y\n",
      "0         1  0\n",
      "1         1  0\n",
      "2         0  0\n",
      "3         0  0\n",
      "4         0  1\n",
      "5         0  1\n",
      "6         1  1\n",
      "7         1  1\n",
      "\n",
      "test set confound count per class: \n",
      "[[0 4]\n",
      " [1 4]]\n",
      "train set, y and confound:\n",
      "    confound  y\n",
      "0          1  0\n",
      "1          1  0\n",
      "2          1  0\n",
      "3          1  0\n",
      "4          1  0\n",
      "5          1  0\n",
      "6          1  0\n",
      "7          1  0\n",
      "8          0  0\n",
      "9          0  0\n",
      "10         0  0\n",
      "11         0  0\n",
      "12         0  0\n",
      "13         0  0\n",
      "14         0  0\n",
      "15         0  0\n",
      "16         0  1\n",
      "17         0  1\n",
      "18         0  1\n",
      "19         0  1\n",
      "20         0  1\n",
      "21         0  1\n",
      "22         0  1\n",
      "23         0  1\n",
      "24         1  1\n",
      "25         1  1\n",
      "26         1  1\n",
      "27         1  1\n",
      "28         1  1\n",
      "29         1  1\n",
      "30         1  1\n",
      "31         1  1\n",
      "\n",
      "train set confound count per class: \n",
      "[[ 0 16]\n",
      " [ 1 16]]\n",
      "test set, y and confound:\n",
      "   confound  y\n",
      "0         1  0\n",
      "1         1  0\n",
      "2         0  0\n",
      "3         0  0\n",
      "4         0  1\n",
      "5         0  1\n",
      "6         1  1\n",
      "7         1  1\n",
      "\n",
      "test set confound count per class: \n",
      "[[0 4]\n",
      " [1 4]]\n",
      "train set, y and confound:\n",
      "    confound  y\n",
      "0          1  0\n",
      "1          1  0\n",
      "2          1  0\n",
      "3          1  0\n",
      "4          1  0\n",
      "5          1  0\n",
      "6          1  0\n",
      "7          1  0\n",
      "8          0  0\n",
      "9          0  0\n",
      "10         0  0\n",
      "11         0  0\n",
      "12         0  0\n",
      "13         0  0\n",
      "14         0  0\n",
      "15         0  0\n",
      "16         0  1\n",
      "17         0  1\n",
      "18         0  1\n",
      "19         0  1\n",
      "20         0  1\n",
      "21         0  1\n",
      "22         0  1\n",
      "23         0  1\n",
      "24         1  1\n",
      "25         1  1\n",
      "26         1  1\n",
      "27         1  1\n",
      "28         1  1\n",
      "29         1  1\n",
      "30         1  1\n",
      "31         1  1\n",
      "\n",
      "train set confound count per class: \n",
      "[[ 0 16]\n",
      " [ 1 16]]\n",
      "test set, y and confound:\n",
      "   confound  y\n",
      "0         1  0\n",
      "1         1  0\n",
      "2         0  0\n",
      "3         0  0\n",
      "4         0  1\n",
      "5         0  1\n",
      "6         1  1\n",
      "7         1  1\n",
      "\n",
      "test set confound count per class: \n",
      "[[0 4]\n",
      " [1 4]]\n",
      "train set, y and confound:\n",
      "    confound  y\n",
      "0          1  0\n",
      "1          1  0\n",
      "2          1  0\n",
      "3          1  0\n",
      "4          1  0\n",
      "5          1  0\n",
      "6          1  0\n",
      "7          1  0\n",
      "8          0  0\n",
      "9          0  0\n",
      "10         0  0\n",
      "11         0  0\n",
      "12         0  0\n",
      "13         0  0\n",
      "14         0  0\n",
      "15         0  0\n",
      "16         0  1\n",
      "17         0  1\n",
      "18         0  1\n",
      "19         0  1\n",
      "20         0  1\n",
      "21         0  1\n",
      "22         0  1\n",
      "23         0  1\n",
      "24         1  1\n",
      "25         1  1\n",
      "26         1  1\n",
      "27         1  1\n",
      "28         1  1\n",
      "29         1  1\n",
      "30         1  1\n",
      "31         1  1\n",
      "\n",
      "train set confound count per class: \n",
      "[[ 0 16]\n",
      " [ 1 16]]\n",
      "test set, y and confound:\n",
      "   confound  y\n",
      "0         1  0\n",
      "1         1  0\n",
      "2         0  0\n",
      "3         0  0\n",
      "4         0  1\n",
      "5         0  1\n",
      "6         1  1\n",
      "7         1  1\n",
      "\n",
      "test set confound count per class: \n",
      "[[0 4]\n",
      " [1 4]]\n",
      "train set, y and confound:\n",
      "    confound  y\n",
      "0          1  0\n",
      "1          1  0\n",
      "2          1  0\n",
      "3          1  0\n",
      "4          1  0\n",
      "5          1  0\n",
      "6          1  0\n",
      "7          1  0\n",
      "8          0  0\n",
      "9          0  0\n",
      "10         0  0\n",
      "11         0  0\n",
      "12         0  0\n",
      "13         0  0\n",
      "14         0  0\n",
      "15         0  0\n",
      "16         0  1\n",
      "17         0  1\n",
      "18         0  1\n",
      "19         0  1\n",
      "20         0  1\n",
      "21         0  1\n",
      "22         0  1\n",
      "23         0  1\n",
      "24         1  1\n",
      "25         1  1\n",
      "26         1  1\n",
      "27         1  1\n",
      "28         1  1\n",
      "29         1  1\n",
      "30         1  1\n",
      "31         1  1\n",
      "\n",
      "train set confound count per class: \n",
      "[[ 0 16]\n",
      " [ 1 16]]\n",
      "test set, y and confound:\n",
      "   confound  y\n",
      "0         1  0\n",
      "1         1  0\n",
      "2         0  0\n",
      "3         0  0\n",
      "4         0  1\n",
      "5         0  1\n",
      "6         1  1\n",
      "7         1  1\n",
      "\n",
      "test set confound count per class: \n",
      "[[0 4]\n",
      " [1 4]]\n"
     ]
    }
   ],
   "source": [
    "css = CounterbalancedStratifiedSplit(X, y, c, n_splits=5, verbose=True)\n",
    "css.check_possible()\n",
    "y_tmp = y[css.subsample_idx]\n",
    "c_tmp = c[css.subsample_idx]\n",
    "print(np.hstack((y_tmp.reshape(len(y_tmp),1), c_tmp.reshape(len(c_tmp),1))))\n",
    "\n",
    "css.find_counterbalanced_seed()\n",
    "splts = css.split(X, y)\n",
    "\n",
    "for spltn in splts:\n",
    "    for i, set_ in enumerate(spltn):\n",
    "        set_type = ['train', 'test'][i]\n",
    "        print('%s set, y and confound:' % set_type)\n",
    "        print(pd.DataFrame({'y': y[set_], 'confound': c[set_]}))\n",
    "        \n",
    "        print('\\n%s set confound count per class: ' % set_type)\n",
    "        print(itemfreq(c[set_]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
