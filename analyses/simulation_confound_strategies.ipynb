{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation confound strategies\n",
    "This notebook evaluates the effectiveness of \"confound strategies\", i.e. their effectiveness of removing the influence of a known confound on machine learning analyses of (simulations of) mutivoxel pattern data. This notebook is meant as a supplement to the [article](link). Together with the notebook with [empirical analyses](empirical_analysis_gender_classification.ipynb), it hopefully complements the article and clarifies our methods and results.\n",
    "\n",
    "Note that this notebook is organized slightly differently than the article. In this notebook, we'll first show you the problem with regressing out a confound from the entire dataset (i.e. not foldwise). We then show you how the correct confound-regression method and the counter-balance method compare in their ability to control for confounding influences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# General packages\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Bunch of scikit-learn stuff\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "# Specific statistics-functions\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Misc.\n",
    "from tqdm import tqdm_notebook\n",
    "from copy import deepcopy\n",
    "from matplotlib_venn import venn3\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Custom code! (install skbold by `pip install skbold`; counterbalance.py is in cwd)\n",
    "from skbold.preproc import ConfoundRegressor\n",
    "from counterbalance import CounterbalancedStratifiedSplit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why confound regression the entire dataset at once is a bad idea\n",
    "We first delve into the issue of below-chance classification we observe when regressing out the confound from the entire dataset at once. As described in the article, we argue that this is narrowing the correlation distribution you'd expect by chance. If you generate random (normal) data matrix of shape $N\\ (samples) \\times K\\ (features)$  - let's call this X - and a vector with binary values (0 or 1) of shape $N \\times K$ - let's call this y.\n",
    "\n",
    "Suppose you implement a cross-validated analysis, in which you fit a linear model (e.g. logistic regression) iteratively in a (let's say) 10-fold cross-validation scheme. Now, suppose you simulate this 1000 times. (Note that this is very similar to the permutation statistics people employ to calculate non-parametric p-values for their classification scores.) You expect the distribution of your (e.g.) accuracy scores to be centered around 50%. However, you'll undoubtely observe some scores below 50%. \n",
    "\n",
    "Remember, linear classifiers are capitalizing on some linear statistical dependence between the features in X and y. This can be (per feature) expressed as the correlation between X and y. We argue that these scores are due a relatively low (absolute) initial correlation between features and y in the *entire* dataset, which subsequently causes opposing statistical dependencies (i.e. flipped signs of correlations) between the train and test-set. \n",
    "\n",
    "To show this association between (below chance) accuracy and the initial correlation between features and y, we've written a simple simulation below. We generate random (normal) data for our X matrix and a vector with random (0, 1) values for y for a given `n_sims` simulations. For each simulation, we keep track of accuracy (averaged over `n_folds`), the initial (absolute) correlation between X and y (averaged over `k_feat` in X), and the proportion of \"sign-flips\" we observe between the correlation of features and y in the train and test-set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def simulate_and_classify_random_data(n_sims, n_samp, k_feat, n_fold):\n",
    "    \n",
    "    pipe = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('svm', SVC(kernel='linear'))\n",
    "    ])\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=n_fold)\n",
    "\n",
    "    results = {'accuracy': [],\n",
    "               'init_corr': [],\n",
    "               'sign_change': []}\n",
    "\n",
    "    acc = np.zeros((n_sims, n_fold))\n",
    "    for i in range(n_sims):\n",
    "        X = np.random.normal(0, 1, size=(n_samp, k_feat))\n",
    "        y = np.repeat([0, 1], repeats=int(n_samp / 2))\n",
    "        \n",
    "        results['init_corr'].append(np.abs(np.corrcoef(np.hstack((X, y[:, np.newaxis])).T))[-1, :-1].mean())\n",
    "        sign_changes = np.zeros(n_fold)\n",
    "        \n",
    "        for ii, (train_idx, test_idx) in enumerate(skf.split(X, y)):\n",
    "\n",
    "            X_train, X_test = X[train_idx], X[test_idx]\n",
    "            y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "            corr_train = np.corrcoef(np.hstack((X_train, y_train[:, np.newaxis])).T)[-1, :-1]\n",
    "            corr_test = np.corrcoef(np.hstack((X_test, y_test[:, np.newaxis])).T)[-1, :-1]\n",
    "            sign_changes[ii] = (np.sign(corr_train) != np.sign(corr_test)).sum() / n_fold\n",
    "            \n",
    "            pipe.fit(X_train, y_train)\n",
    "            acc[i, ii] = pipe.score(X_test, y_test)\n",
    "        results['accuracy'].append(acc[i, :].mean())\n",
    "        results['sign_change'].append(sign_changes.mean())\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we simulate 100 datasets with 100 samples, 5 features, which are analyzed with a linear SVM in a 10-fold cross-validation scheme. We then plot a scatterplot (and linear fit) between accuracy and the initial correlation and between accuracy and the proportion of sign-flips we observe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABCkAAAFOCAYAAACrP0ciAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10e3feb70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = simulate_and_classify_random_data(n_sims=100, n_samp=100, k_feat=5, n_fold=10)\n",
    "plt.figure(figsize=(18, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('Accuracy & init correlation')\n",
    "sns.regplot(y='accuracy', x='init_corr', data=pd.DataFrame(results))\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('Accuracy & proportion sign changes')\n",
    "sns.regplot(y='accuracy', x='sign_change', data=pd.DataFrame(results))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, higher initial correlations lead to above chance accuracy, but importantly (absolute) correlations close(r) to zero lead to below chance classifications! This is fine in this simulation, because we can simulate this many times, across which the mean accuracy is about 50% (y-coordinates of centroid in scatterplots). But you also see that below an average (absolute) correlation across features between X and y of 0.08, below-chance accuracies tend to occur. \n",
    "\n",
    "We think this is happening when you regress out your confound on the entire dataset: you artificially narrow the (absolute) correlation distribution, which leads to an increase in sign-flips and thus negative bias.\n",
    "\n",
    "We show this in another simulation, in which we control the average (absolute) correlation between X and y. We test a range of these correlations and show that lower correlations yield (relatively) more negative bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_and_classify_data_constrained(n_sims, n_samp, k_feat, n_splits, mean_corr):\n",
    "\n",
    "    acc = np.zeros(n_sims)\n",
    "    for i in tqdm_notebook(range(n_sims), desc='%.3f/%i' % (mean_corr, k_feat)):\n",
    "        \n",
    "        # Generate y first\n",
    "        y = np.repeat([0, 1], repeats=int(n_samp / 2))\n",
    "        \n",
    "        attempt = 0\n",
    "        while True:\n",
    "            X = np.random.normal(0, 1, size=(n_samp, k_feat))\n",
    "            \n",
    "            corrs = np.corrcoef(np.hstack((X, y[:, np.newaxis])).T)[:-1, -1]\n",
    "            if (attempt + 1) % 10000 == 0:\n",
    "                \n",
    "                # If it's stuck (likely for many features), let's help it a little bit\n",
    "                while True:\n",
    "                    idx = np.abs(corrs) > mean_corr\n",
    "                    new_X = np.random.normal(0, 1, size=(n_samp, idx.sum()))\n",
    "                    X[:, idx] = new_X\n",
    "                    corrs = np.corrcoef(np.hstack((X, y[:, np.newaxis])).T)[:-1, -1]\n",
    "                    if np.mean(np.abs(corrs)) < mean_corr:\n",
    "                        break\n",
    "            \n",
    "            if np.mean(np.abs(corrs)) < mean_corr:\n",
    "                break\n",
    "            else:\n",
    "                attempt += 1\n",
    "            \n",
    "        # 10-fold stratified CV\n",
    "        cv = StratifiedKFold(n_splits=n_splits)\n",
    "\n",
    "        # Pipeline\n",
    "        pipe = Pipeline([('scale', StandardScaler()), \n",
    "                         ('svc', SVC(kernel='linear'))])\n",
    "\n",
    "        # Cross-validate and predict\n",
    "        scores = cross_val_score(pipe, X, y, cv=n_splits)\n",
    "        acc[i] = scores.mean()\n",
    "        \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac6ec1a22cd54f63bec63bbfcbcb935a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a18e2d4725b4f3faa0f59bff115a735",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f2a69fac8094f5aa7273d7c228942a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8abb0fc768004427b252624f7f102434",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "524ff8df1d634c29bbf8e4af8ffd6d4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c00fc098345e455da1287b8f61444cdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "159471dd8b584703a4e02f0f1a2d215e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccf18f59c1cf4eb29ece64638657e64f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "572cc6c9f4b84107abecb3b05f1cd12e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fd90f66b7a346ef88a1a4b4e37c19f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e1485970adc4e6baf0c739619f2b218",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a4ea055d38542efa2c3aa6a6323d8fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b664345a12b74f859c9e4fed3578a568",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a161bd845f234a4984e6ec1db90c0700",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cb901dbff7a417b9b1efdc29e401fe9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4de86a224004e919b2c21298f08ebe9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd64f81e96c941cc89cf28d3057393ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec5adae821c747acabfdd56bed647f32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a4d6d2b07e444f9a85b55382286a016",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91f7c844245b4bd08833e3769a58cf15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c691cfc34434bda9057e28ae09c841f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "661fb9831246432b9d35ce1ce5056c12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9f8e3e53964458685c23330d0ff8ae9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd8a3844778e4063b224b6bc51548ca8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "def2b6ca438744e39ffda607b7b762ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "035156058bcc4dc68d9aabfa715ea017",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85c34b1959714d1ab1d8823504bf76f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eafc972613fc4e41b152f20656d60516",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61dc079f7c4f406cb01eecf728d3e898",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "332fd7b994f44a72a824cd30509eca84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4185e0522244680949bdbf751b2dc1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4890f73a44a4388aa8792633be29641",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71a5144de7dd47d38c4264c14248ac33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95154897e7064b43a999499878783188",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "245b788668644bdd96445f8281881b5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a697d560fd4a453f8f7b32848f4f64ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7758c98dd01f474dabe4b34dc2865723",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e9d4d3c576b418f80e4520b981b00b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34b015a7eb6449b59e15691c496bf359",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58d67992bdff43d08ab09b1fc07a24d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b773807bc277470d9dd7d582ef70f588",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd5f5ba3ffd142a5837ea8e0becc8d32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "622366680ae94e4e91c8a770818287f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b275f3306854626b56cc8d7d3c0b4ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6808e1b1da948048229dc43a070c9e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "508b6b4376fe41a4a498f9a42bc11a91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12278553b3684c73b1a6936626534671",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf226f7a169e47a280483d0d3c26fe80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab58352f398d4526a20622c4f2685280",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69ccec80c7c742d68410a546f2388932",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3809764aedd745139ced1a7c39f3faf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09c4da055e104ca19f0aa9717b316926",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cad937c9479e450ab5494064db6e477c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03b5cbaa230e4b1cad5515bdc2b9855e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d25441300bb84403b51eb66fcaff26ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c162e7d0a4864562ada9c1fa31427a6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-f2c9773016c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'k_feat'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk_feat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m# print(\"k feat: %i\" % k_feat)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimulate_and_classify_data_constrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_feat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_corr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-f87b020c1cbf>\u001b[0m in \u001b[0;36msimulate_and_classify_data_constrained\u001b[0;34m(n_sims, n_samp, k_feat, n_splits, mean_corr)\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_feat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0mcorrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorrcoef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mattempt\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10000\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36mcorrcoef\u001b[0;34m(x, y, rowvar, bias, ddof)\u001b[0m\n\u001b[1;32m   3161\u001b[0m     \u001b[0mstddev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3162\u001b[0m     \u001b[0mc\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mstddev\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3163\u001b[0;31m     \u001b[0mc\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mstddev\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3165\u001b[0m     \u001b[0;31m# Clip real and imaginary parts to [-1, 1].  This does not guarantee\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mean_corrs = [0.1, 0.09, 0.08, 0.07, 0.06, 0.05, 0.04, 0.03, 0.02, 0.01, 0.005, 0.001]\n",
    "k_feats = [1, 5, 10, 20, 50, 100, 1000]\n",
    "\n",
    "results = dict(mean_corr=[], k_feat=[], acc=[])\n",
    "\n",
    "for mean_corr in mean_corrs:\n",
    "    results['mean_corr'].extend([mean_corr] * len(k_feats))\n",
    "    # print(\"Meancorr: %.2f\" % mean_corr)\n",
    "    for k_feat in k_feats:\n",
    "        results['k_feat'].append(k_feat)\n",
    "        # print(\"k feat: %i\" % k_feat)\n",
    "        acc = simulate_and_classify_data_constrained(10, 100, k_feat, 10, mean_corr)\n",
    "        results['acc'].append(acc.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "arrays must all be same length",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-040a93970dff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfactorplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean_corr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'k_feat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    273\u001b[0m                                  dtype=dtype, copy=copy)\n\u001b[1;32m    274\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_init_dict\u001b[0;34m(self, data, index, columns, dtype)\u001b[0m\n\u001b[1;32m    409\u001b[0m             \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 411\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_arrays_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_init_ndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_arrays_to_mgr\u001b[0;34m(arrays, arr_names, index, columns, dtype)\u001b[0m\n\u001b[1;32m   5494\u001b[0m     \u001b[0;31m# figure out the index, if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5495\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5496\u001b[0;31m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5497\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5498\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mextract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   5542\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5543\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5544\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'arrays must all be same length'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5546\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhave_dicts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: arrays must all be same length"
     ]
    }
   ],
   "source": [
    "sns.factorplot(data=pd.DataFrame(results), x='mean_corr', y='acc', hue='k_feat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A note on how we simulate data\n",
    "In this notebook's simulations, we are going to simulate three variables, with $N$ denoting the number of samples, and $K$ denoting the number of features:\n",
    "\n",
    "- **y**: an $N\\times 1$ vector with values {0, 1}\n",
    "- **c**: an $N\\times 1$ vector with values {0, 1} if continuous, else $c \\sim \\mathcal{N}(0,\\,1)$\n",
    "- **X**: an $N\\times K$ matrix, in each each column $j$ is generated as $X_{j} = \\beta_{1} c + \\beta_{2} y + \\epsilon,\\ \\epsilon \\sim \\mathcal{N}(0, 1)$\n",
    "\n",
    "By tweaking the parameters $\\beta c$ and $\\beta y$, we can specifically \"tune\" how much variance of $y$ is explained by the \"true\" (i.e., unconfounded) signal (which we call $signal\\ R^2$) and how much variance of $y$ is explained by the \"confounded signal\" (i.e., signal in $X$ which is confounded by $c$; we call this $confound\\ R^2$). \n",
    "\n",
    "Basically, in our data-generator (function is defined below) we generate data ($X$, $y$, and $c$) with a specified correlation between $y$ and $c$, $\\rho(cy)$, and subsequently calculate the $confound\\ R^2$ and $signal\\ R^2$ terms. We then check whether these terms correspond to the desired values for these terms; if not, we adjust the generative parameters ($\\beta_{1}$ and $\\beta_{2}$) slightly and try the entire process again until we get the terms that we want.\n",
    "\n",
    "Below, we visualized the $confound\\ R^2$ and $signal\\ R^2$ terms in a Venn-diagram. On the right of the diagram, we describe the steps to get these terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-b8fb7ead515e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m             '001': ''}\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvenn3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubsets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'X'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "mappings = {'100': 'A', '110': 'D', '010': '',\n",
    "            '101': \"B\\n($signal\\ R^2$)\", '111': 'C\\n($confound\\ R^2$)', '011': 'E',\n",
    "            '001': ''}\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "v = venn3(subsets=(1, 1, 0.1, 1, 0.3, 0.1, 0.6), set_labels=('y', 'c', 'X'))\n",
    "\n",
    "for key, value in mappings.items():\n",
    "    v.get_label_by_id(key).set_text(value)\n",
    "    v.get_label_by_id(key).set_size(15)\n",
    "    \n",
    "for label in ['A', 'B', 'C']:\n",
    "    v.get_label_by_id(label).set_size(50)\n",
    "    \n",
    "plt.text(0.7, 0.5, \"$A+B+C+D = 1$\", fontsize=25)\n",
    "plt.text(0.7, 0.4, r\"$B+C+D = \\rho(y.Xc)^2$\", fontsize=25)\n",
    "plt.text(0.7, 0.3, \"$A = 1 - (B+C+D)$\", fontsize=25)\n",
    "plt.text(0.7, 0.2, r\"$C+D = \\rho(y.c)^2$\", fontsize=25)\n",
    "plt.text(0.7, 0.1, \"$B = (B+C+D) - (C+D)$\", fontsize=25)\n",
    "plt.text(0.7, 0.0, r\"$C+E = \\rho(X.c)^2$\", fontsize=25)\n",
    "plt.text(0.7, -.1, \"$D = (B+C+D) - (B+C)$\", fontsize=25)\n",
    "plt.text(0.7, -.2, \"$C = 1 - (A+B+D)$\", fontsize=25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define some functions\n",
    "Below, we define our main data-generation function - `generate_data` - which generates three variables - $X$, $y$, $c$ - corresponding to our predictors, target, and confound, respectively. (But when setting `c=None`, you can also only simulate $X$ and $y$ *without* $c$.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%writefile generate_data.py\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "from tqdm import tqdm_notebook\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def get_r2(iv, dv, stack_intercept=True):\n",
    "    \"\"\" Regress dv onto iv and return r-squared.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    iv : numpy array\n",
    "        Array of shape N (samples) x K (features)\n",
    "    dv : numpy array\n",
    "        Array of shape N (samples) x 1\n",
    "    stack_intercept : bool\n",
    "        Whether to stack an intercept (vector with ones of length N).\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    r2 : float\n",
    "        R-squared model fit.\n",
    "    \"\"\"\n",
    "    \n",
    "    if iv.ndim == 1:\n",
    "        # Add axis if shape is (N,)\n",
    "        iv = iv[:, np.newaxis]\n",
    "    \n",
    "    if stack_intercept:\n",
    "        iv = np.hstack((np.ones((iv.shape[0], 1)), iv))\n",
    "    \n",
    "    beta = np.linalg.lstsq(iv, dv)[0]\n",
    "    dv_hat = iv.dot(beta).squeeze()\n",
    "    r2 = pearsonr(dv_hat, dv)[0] ** 2\n",
    "    if np.isnan(r2):\n",
    "        r2 = 0\n",
    "    \n",
    "    return r2\n",
    "\n",
    "\n",
    "\n",
    "def generate_data(n_samp, k_feat, c_type, corr_cy, signal_r2, confound_r2=None, verbose=False):\n",
    "    \"\"\" Generate data with known (partial) R2 \"structure\".\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n_samp : int\n",
    "        Number of samples (N) in the data (X, y, and c)\n",
    "    k_feat : int\n",
    "        Number of features (K) in the data (X)\n",
    "    c_type : str\n",
    "        Either \"continuous\" or \"categorical\". If categorical,\n",
    "        the data a balanced vector with ones and zeros\n",
    "    corr_cy : float\n",
    "        Number between -1 and 1, specifying the correlation\n",
    "        between the confound (c) and the target (y)\n",
    "    signal_r2 : float\n",
    "        Number between 0 and 1, specifying the explained variance\n",
    "        of y using X, independent of the confound contained in X;\n",
    "        (technically, the semipartial correlation rho(xy.c)\n",
    "    confound_r2 : float or None\n",
    "        Number between 0 and 1 (or None), specifying the shared variance \n",
    "        explained of y of x and c (i.e. the explained variance \n",
    "        of the confound-related information in x). If None,\n",
    "        no confound R2 will be left unspecified (which can be used\n",
    "        to specify a baseline).\n",
    "    verbose : bool\n",
    "        Whether to print (extra) relevant information\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    X : numpy array\n",
    "        Array of shape N (samples) x K (features) with floating point numbers\n",
    "    y : numpy array\n",
    "        Array of shape N (samples) x 1 with binary numbers {0, 1}\n",
    "    c : numpy array\n",
    "        Array of shape N (samples) x 1 with either binary {0, 1}\n",
    "        or continuous (from normal dist, 0 mean, 1 variance) values,\n",
    "        depending on what you set for the `c_type` argument.\n",
    "    \"\"\"\n",
    "    \n",
    "    if n_samp % 2 != 0:\n",
    "        raise ValueError(\"Please select an even number of samples \"\n",
    "                         \"(Makes things easier.)\")\n",
    "\n",
    "    if confound_r2 is not None:\n",
    "        if np.abs(corr_cy) < np.sqrt(confound_r2):\n",
    "            raise ValueError(\"The desired corr_cy value is less than the square \"\n",
    "                             \"root of the desired confound R-squared ... This is \"\n",
    "                             \"impossible to generate.\")\n",
    "        \n",
    "    # Generate y (balanced, 50% class 0, 50% class 1)\n",
    "    y = np.repeat([0, 1], repeats=n_samp / 2)\n",
    "    \n",
    "    # Generate c (confound), with given correlation corr_cy\n",
    "    if c_type == 'categorical':\n",
    "        # Simply shift (\"roll\") y to create correlation using the \"formula\":\n",
    "        # to-shift = N / 4 * (1 - corr_cy)\n",
    "        to_roll = int((n_samp / 4) * (1 - corr_cy))\n",
    "        c = np.roll(y, to_roll)\n",
    "    elif c_type == 'continuous':\n",
    "        # If c is continuous, just sample y + random noise\n",
    "        noise_factor = 100\n",
    "        c = y + np.random.randn(n_samp) * noise_factor\n",
    "        corr = pearsonr(c, y)[0]\n",
    "        \n",
    "        while np.abs(corr - corr_cy) > 0.01:\n",
    "            # Decrease noise if the difference is too big\n",
    "            noise_factor -= 0.01\n",
    "            c = y + np.random.randn(n_samp) * noise_factor\n",
    "            corr = pearsonr(c, y)[0]        \n",
    "    else:\n",
    "        raise ValueError(\"For c_type, please select from {'continuous', \"\n",
    "                         \"'categorical'}\")\n",
    "    \n",
    "    # Define X as a matrix of N-samples by K-features\n",
    "    X = np.zeros((n_samp, k_feat))\n",
    "    \n",
    "    # Pre-allocate arrays for average signal_r2 values and confound_r2 values\n",
    "    signal_r2_values = np.zeros(k_feat)\n",
    "    confound_r2_values = np.zeros(k_feat)\n",
    "    \n",
    "    icept = np.ones((n_samp, 1))\n",
    "    \n",
    "    iterator = tqdm_notebook(np.arange(k_feat)) if verbose else np.arange(k_feat)\n",
    "    for i in iterator:\n",
    "        \n",
    "        # Define generative parameters (gen_beta_y = beta-parameter for y in model of X)\n",
    "        # Upon advice of Steven S., 'reset' generative parameters after each generation\n",
    "        gen_beta_y = 1\n",
    "        gen_beta_c = 1\n",
    "        noise_factor = 1\n",
    "        \n",
    "        while True:\n",
    "            \n",
    "            should_continue = False\n",
    "            \n",
    "            # Generate X as a linear combination of y, c, and random noise\n",
    "            this_c = 0 if confound_r2 is None else c\n",
    "            this_X = (gen_beta_y * y + gen_beta_c * this_c + np.random.randn(n_samp) * noise_factor)\n",
    "            this_X = this_X[:, np.newaxis]\n",
    "            \n",
    "            # Fit y = b1X\n",
    "            y_x_r2 = get_r2(iv=this_X, dv=y, stack_intercept=True)  # B + C\n",
    "            \n",
    "            # Increase/decrease noise if difference observed r(yx)**2 is too big/small,\n",
    "            # because if y_x_r2 < (signal_r2 + confound_r2), you won't find proper data anyway\n",
    "            tmp_confound_r2 = 0 if confound_r2 is None else confound_r2\n",
    "            difference_obs_vs_desired = y_x_r2 - (signal_r2 + tmp_confound_r2)\n",
    "            if np.abs(difference_obs_vs_desired) > 0.001:\n",
    "                # If correlation too small/big, adjust noise factor and CONTINUE\n",
    "                if difference_obs_vs_desired < 0:\n",
    "                    noise_factor -= 0.01\n",
    "                else:\n",
    "                    noise_factor += 0.01\n",
    "                continue\n",
    "            \n",
    "            if confound_r2 is None:\n",
    "                # We don't care about confound_r2\n",
    "                unique_var_x = y_x_r2\n",
    "            else:\n",
    "                # Fit y = b1X + b2C\n",
    "                y_xc_r2 = get_r2(iv=np.hstack((this_X, c[:, np.newaxis])), dv=y,\n",
    "                             stack_intercept=True)  # B + C + D\n",
    "                resid_y = 1 - y_xc_r2  # A = 1 - (B + C + D)\n",
    "\n",
    "                # Fit y = b1C\n",
    "                y_c_r2 = get_r2(iv=c, dv=y, stack_intercept=True)  # C + D\n",
    "                unique_var_x = y_xc_r2 - y_c_r2  # B\n",
    "            \n",
    "            # Increase/decrease generative param for y if difference \n",
    "            # r(yx.c) is too small/big ...\n",
    "            difference_obs_vs_desired = unique_var_x - signal_r2\n",
    "            if np.abs(difference_obs_vs_desired) > 0.01:\n",
    "                if difference_obs_vs_desired < 0:\n",
    "                    gen_beta_y += 0.01\n",
    "                else:\n",
    "                    gen_beta_y -= 0.01\n",
    "                \n",
    "                if confound_r2 is None:\n",
    "                    continue\n",
    "                else:\n",
    "                    should_continue = True\n",
    "            else:\n",
    "                if confound_r2 is None:\n",
    "                    break\n",
    "                    \n",
    "            unique_var_c = y_xc_r2 - y_x_r2  # D\n",
    "            shared_var_xc = 1 - resid_y - unique_var_x - unique_var_c  # C\n",
    "\n",
    "            # Also check if shared variance of c and x (component C) is appropriate;\n",
    "            # if not, adjust generative parameter and CONTINUE\n",
    "            difference_obs_vs_desired = shared_var_xc - confound_r2\n",
    "            if np.abs(difference_obs_vs_desired) > 0.01:\n",
    "                if difference_obs_vs_desired < 0:\n",
    "                    gen_beta_c += 0.01\n",
    "                else:\n",
    "                    gen_beta_c -= 0.01\n",
    "                should_continue = True\n",
    "            \n",
    "            if should_continue:\n",
    "                continue\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        # If we didn't encounter a \"break\" statement, we must have found\n",
    "        # data with the correct specifications ...\n",
    "        X[:, i] = this_X.squeeze()\n",
    "        signal_r2_values[i] = unique_var_x\n",
    "        if confound_r2 is not None:\n",
    "            confound_r2_values[i] = shared_var_xc\n",
    "        \n",
    "    if verbose:\n",
    "        print(\"Signal r2: %.3f\" % signal_r2_values.mean())\n",
    "        \n",
    "        if confound_r2 is not None:\n",
    "            print(\"Confound r2: %.3f\" % confound_r2_values.mean())\n",
    "        \n",
    "        \n",
    "        plt.figure(figsize=(15, 5))\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.imshow(np.corrcoef(X.T), aspect='auto', cmap='RdBu')\n",
    "        plt.title(\"Correlations between features\")\n",
    "        plt.colorbar()\n",
    "        plt.grid('off')\n",
    "        \n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.title(\"Signal R2 values\")\n",
    "        plt.hist(signal_r2_values, bins='auto')\n",
    "        \n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.title(\"Confound R2 values\")\n",
    "        plt.hist(confound_r2_values, bins='auto')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    if confound_r2 is None:\n",
    "        return X, y\n",
    "    else:\n",
    "        return X, y, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing!\n",
    "data_args = dict(n_samp=240, k_feat=10, c_type='categorical', corr_cy=0.8,\n",
    "                 signal_r2=0.01, confound_r2=0.0, verbose=True)\n",
    "X, y, c = generate_data(**data_args)\n",
    "res = run_without_confound_control(X, y, c, pipeline, n_splits, data_args)\n",
    "res['score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrs = np.zeros(100)\n",
    "for i in range(100):\n",
    "    x = np.random.normal(0, 1, (100, 26))\n",
    "    corrs[i] = np.max([np.abs(pearsonr(x[:, i], x[:, -1])[0]) for i in range(x.shape[1] - 1)])\n",
    "print(np.abs(corrs).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we define several functions to quickly run classification analyses using different confound-strategies we're evaluating in this notebook:\n",
    "\n",
    "- **none**: just run a classification analysis (predict $y$ from $X$) without treating the confound ($c$)\n",
    "- **wdcr** (whole-dataset confound regression): regress out $c$ from $X$ on the whole dataset, then run a (cross-validated) classification analysis\n",
    "- **fwcr** (foldwise confound regression): first regress out $c$ from $X$ per fold, then run a classification analysis (predict $y$ from $X$)\n",
    "- **cb** (counterbalance): first subsample $X$ and $y$ until $\\rho(yc) \\approx 0$, then run a classification analysis (predict $y$ from $X$; also, it's made sure that $\\rho(yc) = 0$ also in *each fold*!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_without_confound_control(X, y, c, pipeline, n_splits, arg_dict):\n",
    "    \"\"\" Run a classification analysis using without controlling for confounds.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : numpy array\n",
    "        Array of shape N (samples) x K (features) with floating point numbers\n",
    "    y : numpy array\n",
    "        Array of shape N (samples) x 1 with binary numbers {0, 1}\n",
    "    c : numpy array\n",
    "        Array of shape N (samples) x 1 with either binary {0, 1}\n",
    "        or continuous (from normal dist, 0 mean, 1 variance) values\n",
    "    pipeline : Pipeline-object\n",
    "        A scikit-learn Pipeline-object\n",
    "    n_splits : int\n",
    "        Number of splits to generate in the K-fold routine\n",
    "    arg_dict : dict\n",
    "        Dictionary with arguments used in data generation\n",
    "        (i.e. args fed to generate_data function)\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    results : pandas DataFrame\n",
    "        DataFrame with data parameters (from arg-dict) and fold-wise scores.\n",
    "    \"\"\"\n",
    "    \n",
    "    results = pd.concat([pd.DataFrame(arg_dict, index=[i]) for i in range(n_splits)])\n",
    "    results['method'] = ['none'] * n_splits\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=n_splits)\n",
    "    scores = np.zeros(n_splits)\n",
    "    \n",
    "    for i, (train_idx, test_idx) in enumerate(skf.split(X, y)):\n",
    "        X_train, y_train = X[train_idx], y[train_idx]\n",
    "        X_test, y_test = X[test_idx], y[test_idx]\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        scores[i] = pipeline.score(X_test, y_test)\n",
    "        \n",
    "    results['score'] = scores\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def run_with_wholedataset_confound_regression(X, y, c, pipeline, n_splits, arg_dict):\n",
    "    \"\"\" Run a classification analysis using without controlling for confounds.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : numpy array\n",
    "        Array of shape N (samples) x K (features) with floating point numbers\n",
    "    y : numpy array\n",
    "        Array of shape N (samples) x 1 with binary numbers {0, 1}\n",
    "    c : numpy array\n",
    "        Array of shape N (samples) x 1 with either binary {0, 1}\n",
    "        or continuous (from normal dist, 0 mean, 1 variance) values\n",
    "    pipeline : Pipeline-object\n",
    "        A scikit-learn Pipeline-object\n",
    "    n_splits : int\n",
    "        Number of splits to generate in the K-fold routine\n",
    "    arg_dict : dict\n",
    "        Dictionary with arguments used in data generation\n",
    "        (i.e. args fed to generate_data function)\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    results : pandas DataFrame\n",
    "        DataFrame with data parameters (from arg-dict) and fold-wise scores.\n",
    "    \"\"\"\n",
    "    \n",
    "    results = pd.concat([pd.DataFrame(arg_dict, index=[i]) for i in range(n_splits)])\n",
    "    results['method'] = ['wdcr'] * n_splits\n",
    "    \n",
    "    # Regress out c from X\n",
    "    cr = ConfoundRegressor(confound=c, fit_idx=np.arange(y.size), cross_validate=True)\n",
    "    X = cr.fit_transform(X)\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=n_splits)\n",
    "    scores = np.zeros(n_splits)\n",
    "    \n",
    "    for i, (train_idx, test_idx) in enumerate(skf.split(X, y)):\n",
    "        X_train, y_train = X[train_idx], y[train_idx]\n",
    "        X_test, y_test = X[test_idx], y[test_idx]\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        scores[i] = pipeline.score(X_test, y_test)\n",
    "        \n",
    "    results['score'] = scores\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def run_with_confound_regression(X, y, c, pipeline, n_splits, arg_dict):\n",
    "    \"\"\" Run a classification analysis using without controlling for confounds.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : numpy array\n",
    "        Array of shape N (samples) x K (features) with floating point numbers\n",
    "    y : numpy array\n",
    "        Array of shape N (samples) x 1 with binary numbers {0, 1}\n",
    "    c : nu1mpy array\n",
    "        Array of shape N (samples) x 1 with either binary {0, 1}\n",
    "        or continuous (from normal dist, 0 mean, 1 variance) values\n",
    "    pipeline : Pipeline-object\n",
    "        A scikit-learn Pipeline-object\n",
    "    n_splits : int\n",
    "        Number of splits to generate in the K-fold routine\n",
    "    arg_dict : dict\n",
    "        Dictionary with arguments used in data generation\n",
    "        (i.e. args fed to generate_data function)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    results : pandas DataFrame\n",
    "        DataFrame with data parameters (from arg-dict) and fold-wise scores.\n",
    "    \"\"\"\n",
    " \n",
    "    results = pd.concat([pd.DataFrame(arg_dict, index=[i]) for i in range(n_splits)])\n",
    "    results['method'] = ['fwcr'] * n_splits\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=n_splits)\n",
    "    scores = np.zeros(n_splits)\n",
    "    \n",
    "    for i, (train_idx, test_idx) in enumerate(skf.split(X, y)):\n",
    "        \n",
    "        cr = ConfoundRegressor(confound=c, fit_idx=train_idx, cross_validate=True)\n",
    "        this_pipe = deepcopy(pipeline).steps\n",
    "        this_pipe.insert(0, ('regress', cr))\n",
    "        this_pipe = Pipeline(this_pipe)\n",
    "        X_train, y_train = X[train_idx], y[train_idx]\n",
    "        X_test, y_test = X[test_idx], y[test_idx]\n",
    "        this_pipe.fit(X_train, y_train)\n",
    "        scores[i] = this_pipe.score(X_test, y_test)\n",
    "        \n",
    "    results['score'] = scores\n",
    "    \n",
    "    return results\n",
    "\n",
    "def run_with_counterbalancing(X, y, c, pipeline, n_splits, arg_dict, \n",
    "                              c_type='categorical', metric='corr', threshold=0.01, verbose=False):\n",
    "    \"\"\" Run a classification analysis using without controlling for confounds.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : numpy array\n",
    "        Array of shape N (samples) x K (features) with floating point numbers\n",
    "    y : numpy array\n",
    "        Array of shape N (samples) x 1 with binary numbers {0, 1}\n",
    "    c : numpy array\n",
    "        Array of shape N (samples) x 1 with either binary {0, 1}\n",
    "        or continuous (from normal dist, 0 mean, 1 variance) values\n",
    "    pipeline : Pipeline-object\n",
    "        A scikit-learn Pipeline-object\n",
    "    n_splits : int\n",
    "        Number of splits to generate in the K-fold routine\n",
    "    arg_dict : dict\n",
    "        Dictionary with arguments used in data generation\n",
    "        (i.e. args fed to generate_data function)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    results : pandas DataFrame\n",
    "        DataFrame with data parameters (from arg-dict) and fold-wise scores.\n",
    "    \"\"\"\n",
    "\n",
    "    results = pd.concat([pd.DataFrame(arg_dict, index=[i]) for i in range(n_splits)])\n",
    "    results['method'] = ['cb'] * n_splits\n",
    "\n",
    "    results_corr = pd.concat([pd.DataFrame(arg_dict, index=[i]) for i in range(arg_dict['k_feat']*2)])\n",
    "    results_corr['ki'] = np.tile(np.arange(arg_dict['k_feat']), reps=2)\n",
    "    results_corr['before_after'] = ['before'] * arg_dict['k_feat'] + ['after'] * arg_dict['k_feat']\n",
    "    \n",
    "    corrs_xc_before = [pearsonr(c, X[:, i])[0] for i in range(X.shape[1])]\n",
    "    corrs_xy_before = [pearsonr(y, X[:, i])[0] for i in range(X.shape[1])]\n",
    "    \n",
    "    skf = CounterbalancedStratifiedSplit(X, y, c, n_splits=n_splits, c_type=c_type, verbose=verbose)\n",
    "    try:\n",
    "        skf.check_counterbalance_and_subsample()\n",
    "    except ValueError as ve:\n",
    "        results['score'] = np.zeros(n_splits)\n",
    "        corrs_xc_after = np.zeros_like(corrs_xc_before)\n",
    "        corrs_xy_after = np.zeros_like(corrs_xy_before)\n",
    "        results_corr['cx'] = np.concatenate((corrs_xc_before, corrs_xc_after))\n",
    "        results_corr['xy'] = np.concatenate((corrs_xy_before, corrs_xy_after))\n",
    "        return results, results_corr\n",
    "\n",
    "    X, y, c = X[skf.subsample_idx], y[skf.subsample_idx], c[skf.subsample_idx]    \n",
    "    corrs_xc_after = np.array([pearsonr(c, X[:, i])[0] for i in range(X.shape[1])])\n",
    "    corrs_xy_after = np.array([pearsonr(y, X[:, i])[0] for i in range(X.shape[1])])\n",
    "    results_corr['cx'] = np.concatenate((corrs_xc_before, corrs_xc_after))\n",
    "    results_corr['xy'] = np.concatenate((corrs_xy_before, corrs_xy_after))\n",
    "    \n",
    "    scores = np.zeros(n_splits)\n",
    "\n",
    "    for i, (train_idx, test_idx) in enumerate(skf.split(X, y)):\n",
    "        X_train, y_train, c_train = X[train_idx], y[train_idx], c[train_idx]\n",
    "        X_test, y_test, c_test = X[test_idx], y[test_idx], c[test_idx]\n",
    "        pipeline.fit(np.hstack((X_train, c_train[:, np.newaxis])), y_train)\n",
    "        scores[i] = pipeline.score(np.hstack((X_test, c_test[:, np.newaxis])), y_test)\n",
    "    \n",
    "    results['score'] = scores\n",
    "    \n",
    "    return results, results_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixed parameters / settings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', SVC(kernel='linear'))\n",
    "])\n",
    "\n",
    "n_splits = 10  # i.e. 10-fold cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario 1: below-chance accuracy in whole dataset confound regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_args = dict(n_samp=240, k_feat=5, c_type='categorical', corr_cy=None,\n",
    "                 signal_r2=0.1, confound_r2=None, verbose=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario 1: what happens when we vary *confound $R^2$* and *$\\rho(cy)$*?\n",
    "... or, in other words, what happens when we increase the amount of confounded \"signal\" in X (area *C* in the venn-diagram) and the initial correlation between the confound (c) and the target (y)?\n",
    "\n",
    "We evaluate the following values for the parameter $\\rho(cy)$:\n",
    "- $\\rho(cy) \\in \\{0.25, 0.3, 0.35..., 0.85\\}$\n",
    "\n",
    "We set the range of values (in steps of 0.05) for $confound\\ R^2$ dynamically, because the maximum value for $confound\\ R^2$ depends on the $\\rho(cy)$ parameter. For example, we cannot set $confound\\ R^2 = 0.5$ when $\\rho(cy) = 0.6$, because $\\sqrt{0.5} > 0.6$. Thus:\n",
    "\n",
    "- $confound\\ R^2 \\in \\{0.00, 0.05, ..., \\rho(cy)^2 - (\\rho(cy)^2\\ mod\\ 0.05)\\}$\n",
    "\n",
    "And we'll use the following fixed parameters:\n",
    "- $N = 240$\n",
    "- $K = 5$\n",
    "- $signal\\ R^2=0.1$\n",
    "\n",
    "Importantly, we also track the correlations $\\rho(xy)$ and $\\rho(xc)$ before and after counterbalancing, because there is something weird going on (as we'll explain later)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confound = categorical\n",
    "Here, the confound is categorical with values {0, 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We do it three times for robustness\n",
    "simulations = 1\n",
    "\n",
    "# Specify arguments for data generations (we'll set corr_cy and confound_r2 later)\n",
    "data_args = dict(n_samp=240, k_feat=5, c_type='categorical', corr_cy=None,\n",
    "                 signal_r2=0.1, confound_r2=None, verbose=False)\n",
    "\n",
    "# The values for corr_cy to loop over\n",
    "corr_cy_vec = [0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85]\n",
    "\n",
    "# The confound_r2 values to loop over\n",
    "confound_r2_vecs = [np.arange(0, corr_cy ** 2, 0.05)\n",
    "                    for corr_cy in corr_cy_vec]\n",
    "\n",
    "# The 'baseline scores' to keep track of (scores on data generated without\n",
    "# any influence of the confound)\n",
    "baseline_scores = np.zeros((simulations, len(corr_cy_vec)))\n",
    "\n",
    "results_sce1 = []\n",
    "results_corr_sce1 = []\n",
    "\n",
    "# Loop over simulations\n",
    "for sim in np.arange(simulations):\n",
    "\n",
    "    print(\"Simulation: %i\" % (sim + 1))\n",
    "    \n",
    "    # Loop over values for corr_cy\n",
    "    for i, corr_cy in enumerate(corr_cy_vec):\n",
    "        data_args.update(corr_cy=corr_cy)\n",
    "        data_args.update(confound_r2=None)\n",
    "        Xbase, ybase = generate_data(**data_args) \n",
    "        baseline_scores[sim, i] = cross_val_score(pipeline, Xbase, ybase, cv=n_splits).mean()\n",
    "\n",
    "        confound_r2_vec = confound_r2_vecs[i]\n",
    "        print(\"corr_cy: %.3f, confound_r2: %r\" % (corr_cy, np.around(confound_r2_vec, 3).tolist()))\n",
    "        \n",
    "        # Loop over values for confound_r2\n",
    "        for ii, confound_r2 in enumerate(confound_r2_vec):\n",
    "            data_args.update(confound_r2=confound_r2)\n",
    "            X, y, c = generate_data(**data_args)\n",
    "            results_sce1.append(run_without_confound_control(X, y, c, pipeline, n_splits, data_args))\n",
    "            results_sce1.append(run_with_wholedataset_confound_regression(X, y, c, pipeline, n_splits, data_args))\n",
    "            results_sce1.append(run_with_confound_regression(X, y, c, pipeline, n_splits, data_args))    \n",
    "            res, corrs = run_with_counterbalancing(X, y, c, pipeline, n_splits, c_type='categorical',\n",
    "                                                   arg_dict=data_args)\n",
    "            results_corr_sce1.append(corrs)\n",
    "            results_sce1.append(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot it! The plot consists of subplots organized in three columns and six rows. Each *row* contains the results from a different $\\rho(cy)$ setting. The first row shows results from data with $\\rho(cy) = 0.4$, the second from data with $\\rho(cy) = 0.5$, etc. \n",
    "\n",
    "In the first column, the mean accuracy across folds is plotted for a range of $confound\\ R^2$ values. Note that the *specific* range of $confound\\ R^2$ values depends on the $\\rho(cy)$ value, viz,. you cannot generate data with $confound\\ R^2 > \\rho(cy)^2$. These mean accuracies across $confound\\ R^2$ values is plotted for the three methods ('none', 'cb', and 'regress') as well as a (dashed orange) line indicating the performance if there would be no $confound\\ R^2$, only $signal\\ R^2$.\n",
    "\n",
    "The second and third rows provide some extra information about what is happening in the counterbalance method. \n",
    "The second column shows $\\rho(xc)$, i.e. the mean correlation between our features (from X) and the confound (c), both **before** subsampling (blue) and **after** subsampling (green). The third column shows $\\rho(xy)$, i.e. the mean correlation between our features (from X) and the target (y), again both **before** and **after** subsampling.\n",
    "\n",
    "Note that if the counterbalancing yields too few samples (i.e. has to undersample so much that it doesn't leave any samples), then score is set to 0 (also for the correlations $\\rho(cx)$ and $\\rho(xy)$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.25)\n",
    "df_sce1 = pd.concat(results_sce1)\n",
    "df_corrs_sce1 = pd.concat(results_corr_sce1)\n",
    "fig, axes = plt.subplots(len(corr_cy_vec), 3, figsize=(15, 35), gridspec_kw={'width_ratios': [1.5, 1, 1]},\n",
    "                         sharex=True, sharey=False)\n",
    "\n",
    "for i in range(len(axes)):\n",
    "    tmp = df_sce1[df_sce1.corr_cy == corr_cy_vec[i]]\n",
    "    axes[i][0].set_title(r\"$\\rho(cy) = %.2f$\" % corr_cy_vec[i])\n",
    "    g = sns.pointplot(x='confound_r2', y='score', hue='method',\n",
    "                   data=tmp, size=5, aspect=2,\n",
    "                   palette=\"muted\", ax=axes[i][0])\n",
    "    \n",
    "    if i != 0:\n",
    "        g.legend_.remove()\n",
    "    \n",
    "    if i != len(axes) - 1:\n",
    "        axes[i][0].set_xlabel('')\n",
    "    \n",
    "    g.set_ylim((-0.1, 1.1))\n",
    "    axes[i][0].axhline(y=0.5, c='black', ls='--')\n",
    "    axes[i][0].axhline(y=baseline_scores[:, i].mean(), c='orange', ls='--')\n",
    "\n",
    "    tmp = df_corrs_sce1[df_corrs_sce1.corr_cy == corr_cy_vec[i]]\n",
    "    axes[i][1].set_title(r'$\\rho(xc)$')\n",
    "    g = sns.barplot(x=\"confound_r2\", y=\"cx\", hue=\"before_after\", data=tmp, ax=axes[i][1])\n",
    "    g.legend_.remove()\n",
    "    axes[i][1].legend(loc='best')\n",
    "    axes[i][2].set_title(r'$\\rho(xy)$')\n",
    "    g.set_ylim((-0.6, 1))\n",
    "    g = sns.barplot(x=\"confound_r2\", y=\"xy\", hue=\"before_after\", data=tmp, ax=axes[i][2])\n",
    "    g.legend_.remove()\n",
    "    g.set_ylim((-0.6, 1))\n",
    "    \n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the blue line (confound not controlled for) increases when $confound\\ R^2$ increases, as you would expect. You also see that confound regression (green line) nicely follows the orange dashed line, which indicates the scanario in which confound plays no role. \n",
    "\n",
    "Lastly, we an interesting (disturbing?) thing happening with the counterbalancing method: when $\\rho(cy)$ increases, the counterbalancing method starts to show positive bias, i.e., scores higher than you should see when the confound is adequately dealt with. The third column of graphs shows the reason: subsampling seems to increase the correlation between the features (X) and y (i.e. $signal\\ R^2$ seems to increase)!\n",
    "\n",
    "This is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mappings = {'100': 'A', '110': 'D', '010': '',\n",
    "            '101': \"B\\n($signal\\ R^2$)\", '111': 'C\\n($confound\\ R^2$)', '011': 'E',\n",
    "            '001': ''}\n",
    "\n",
    "plt.figure(figsize=(20, 20))\n",
    "plt.subplot(1, 2, 1)\n",
    "v = venn3(subsets=(1, 1, 0.1, 1, 0.3, 0.1, 0.6), set_labels=('y', 'c', 'X'))\n",
    "\n",
    "for key, value in mappings.items():\n",
    "    v.get_label_by_id(key).set_text(value)\n",
    "    v.get_label_by_id(key).set_size(15)\n",
    "    \n",
    "for label in ['A', 'B', 'C']:\n",
    "    v.get_label_by_id(label).set_size(50)\n",
    "\n",
    "plt.subplot(1, 2, 2)    \n",
    "v = venn3(subsets=(1.5, 1.5, 0.0, 1, 1, 1, 0.0), set_labels=('y', 'c', 'X'))\n",
    "\n",
    "for key, value in mappings.items():\n",
    "    if key in ['111', '110']:\n",
    "        continue\n",
    "    v.get_label_by_id(key).set_text(value)\n",
    "    v.get_label_by_id(key).set_size(15)\n",
    "    \n",
    "for label in ['A', 'B', 'C']:\n",
    "    v.get_label_by_id(label).set_size(50)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, what must happen is that component **B** (right diagram) must increase with increasing $\\rho(cy)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario 3: what happens when we vary $\\rho(y.X\\ |\\ c)$?\n",
    "... or, in other words, what happens in we increase the true (unconfounded) signal?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confound = categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "permutations = 1\n",
    "\n",
    "data_args = dict(n_samp=240, k_feat=5, c_type='categorical', corr_cy=0.65,\n",
    "                 signal_r2=None, confound_r2=None, verbose=False)\n",
    "    \n",
    "signal_r2_vec = [0.00, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3]\n",
    "confound_r2_vec = [0.00, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35]\n",
    "baseline_scores = np.zeros((permutations, len(signal_r2_vec)))\n",
    "\n",
    "results = []\n",
    "results_corr = []\n",
    "for perm in np.arange(permutations):\n",
    "\n",
    "    print(\"Permutation: %i\" % (perm + 1))\n",
    "\n",
    "    for i, signal_r2 in enumerate(signal_r2_vec):\n",
    "        data_args.update(confound_r2=None)\n",
    "        data_args.update(signal_r2=signal_r2)\n",
    "        base_args = deepcopy(data_args)\n",
    "        Xbase, ybase = generate_data(**base_args) \n",
    "        baseline_scores[perm, i] = cross_val_score(pipeline, Xbase, ybase, cv=n_splits).mean()\n",
    "        \n",
    "        for ii, confound_r2 in enumerate(confound_r2_vec):\n",
    "            data_args.update(confound_r2=confound_r2)\n",
    "            X, y, c = generate_data(**data_args)\n",
    "            results.append(run_without_confound_control(X, y, c, pipeline, n_splits, data_args))\n",
    "            results.append(run_with_confound_regression(X, y, c, pipeline, n_splits, data_args))\n",
    "            res, corrs = run_with_counterbalancing(X, y, c, pipeline, n_splits, data_args, c_type='categorical',\n",
    "                                                   metric='corr', threshold=0.01)\n",
    "            results_corr.append(corrs)\n",
    "            results.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.25)\n",
    "df = pd.concat(results)\n",
    "df_corrs = pd.concat(results_corr)\n",
    "fig, axes = plt.subplots(len(signal_r2_vec), 3, figsize=(15, 25), gridspec_kw={'width_ratios': [1.5, 1, 1]})\n",
    "\n",
    "for i in range(len(axes)):\n",
    "    tmp = df[df.signal_r2 == signal_r2_vec[i]]\n",
    "    axes[i][0].set_title(\"$Signal R^2 = %.3f$\" % signal_r2_vec[i])\n",
    "    g = sns.pointplot(x='confound_r2', y='score', hue='method',\n",
    "                      data=tmp, size=5, aspect=2,\n",
    "                      palette=\"muted\", ax=axes[i][0])\n",
    "    g.legend_.remove()\n",
    "    \n",
    "    if i != len(axes) - 1:\n",
    "        axes[i][0].set_xlabel('')\n",
    "    \n",
    "    g.set_ylim((-0.1, 1.1))\n",
    "    axes[i][0].axhline(y=0.5, c='black', ls='--')\n",
    "    axes[i][0].axhline(y=baseline_scores[:, i].mean(axis=0), c='orange', ls='--')\n",
    "\n",
    "    tmp = df_corrs[df_corrs.signal_r2 == signal_r2_vec[i]]\n",
    "    axes[i][1].set_title(r'$\\rho(xc)$')\n",
    "    g = sns.barplot(x=\"confound_r2\", y=\"cx\", hue=\"before_after\", data=tmp, ax=axes[i][1])\n",
    "    g.legend_.remove()\n",
    "    axes[i][1].legend(loc='best')\n",
    "    axes[i][2].set_title(r'$\\rho(xy)$')\n",
    "    g = sns.barplot(x=\"confound_r2\", y=\"xy\", hue=\"before_after\", data=tmp, ax=axes[i][2])\n",
    "    g.legend_.remove()\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same plot, but x-axis and factor (signal r2) reversed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.25)\n",
    "df = pd.concat(results)\n",
    "df_corrs = pd.concat(results_corr)\n",
    "fig, axes = plt.subplots(len(confound_r2_vec), 3, figsize=(15, 55), gridspec_kw={'width_ratios': [1.5, 1, 1]})\n",
    "\n",
    "for i in range(len(axes)):\n",
    "    tmp = df[df.confound_r2 == confound_r2_vec[i]]\n",
    "    axes[i][0].set_title(\"$Confound R^2 = %.3f$\" % confound_r2_vec[i])\n",
    "    g = sns.pointplot(x='signal_r2', y='score', hue='method',\n",
    "                      data=tmp, size=5, aspect=2,\n",
    "                      palette=\"muted\", ax=axes[i][0])\n",
    "    g.legend_.remove()\n",
    "      \n",
    "    axes[i][0].plot(np.arange(len(signal_r2_vec)), baseline_scores.mean(axis=0), color='orange', ls='--')\n",
    "    \n",
    "    if i != len(axes) - 1:\n",
    "        axes[i][0].set_xlabel('')\n",
    "    \n",
    "    g.set_ylim((-0.1, 1.1))\n",
    "    axes[i][0].axhline(y=0.5, c='black', ls='--')\n",
    "    # axes[i][0].plot(x=np.arange(6), y=baseline_scores.mean(axis=0), c='orange', ls='--')\n",
    "\n",
    "    tmp = df_corrs[df_corrs.confound_r2 == confound_r2_vec[i]]\n",
    "    axes[i][1].set_title(r'$\\rho(xc)$')\n",
    "    g = sns.barplot(x=\"signal_r2\", y=\"cx\", hue=\"before_after\", data=tmp, ax=axes[i][1])\n",
    "    g.legend_.remove()\n",
    "    axes[i][1].legend(loc='best')\n",
    "    axes[i][2].set_title(r'$\\rho(xy)$')\n",
    "    g = sns.barplot(x=\"signal_r2\", y=\"xy\", hue=\"before_after\", data=tmp, ax=axes[i][2])\n",
    "    g.legend_.remove()\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confound = continuous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "permutations = 1\n",
    "\n",
    "data_args = dict(n_samp=240, k_feat=5, c_type='continuous', corr_cy=0.8,\n",
    "                 signal_r2=None, confound_r2=None, verbose=False)\n",
    "    \n",
    "signal_r2_vec = [0.00, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3]\n",
    "confound_r2_vec = [0.00, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6]\n",
    "baseline_scores = np.zeros((permutations, len(signal_r2_vec)))\n",
    "\n",
    "results = []\n",
    "results_corr = []\n",
    "for perm in np.arange(permutations):\n",
    "\n",
    "    print(\"Permutation: %i\" % (perm + 1))\n",
    "\n",
    "    for i, signal_r2 in enumerate(signal_r2_vec):\n",
    "        print('Signal r2: %.3f' % signal_r2)\n",
    "        data_args.update(signal_r2=signal_r2)\n",
    "        base_args = deepcopy(data_args)\n",
    "        base_args['c_type'] = 'none'\n",
    "        Xbase, ybase = generate_data(**base_args) \n",
    "        baseline_scores[perm, i] = cross_val_score(pipeline, Xbase, ybase, cv=n_splits).mean()\n",
    "        \n",
    "        for ii, confound_r2 in enumerate(confound_r2_vec):\n",
    "            print('Confound r2: %.3f' % confound_r2)\n",
    "            data_args.update(confound_r2=confound_r2)\n",
    "            X, y, c = generate_data(**data_args)\n",
    "            results.append(run_without_confound_control(X, y, c, pipeline, n_splits, data_args))\n",
    "            results.append(run_with_confound_regression(X, y, c, pipeline, n_splits, data_args))\n",
    "            res, corrs = run_with_counterbalancing(X, y, c, pipeline, n_splits, data_args, c_type='continuous',\n",
    "                                                   metric='corr', threshold=0.01)\n",
    "            results_corr.append(corrs)\n",
    "            results.append(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EVERYTHING BELOW IS IRRELEVANT FOR NOW (LUKAS' PLAYGROUND)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K_FEAT = 5\n",
    "data_args = dict(n_samp=240, k_feat=K_FEAT, c_type='categorical', corr_cy=0.7,\n",
    "                 signal_r2=0.1, confound_r2=0.49, verbose=False)\n",
    "X, y, c = generate_data(**data_args)\n",
    "\n",
    "corrs_xc_before = [pearsonr(c, X[:, i])[0] for i in range(X.shape[1])]\n",
    "corrs_xy_before = [pearsonr(y, X[:, i])[0] for i in range(X.shape[1])]\n",
    "\n",
    "skf = CounterbalancedStratifiedSplit(X, y, c, n_splits=10, c_type='categorical', verbose=False)\n",
    "skf.check_counterbalance_and_subsample()\n",
    "X, y, c = X[skf.subsample_idx], y[skf.subsample_idx], c[skf.subsample_idx]    \n",
    "corrs_xc_after = np.array([pearsonr(c, X[:, i])[0] for i in range(X.shape[1])])\n",
    "corrs_xy_after = np.array([pearsonr(y, X[:, i])[0] for i in range(X.shape[1])])\n",
    "\n",
    "scores = np.zeros(n_splits)\n",
    "corrs_xy_train = np.zeros((10, K_FEAT))\n",
    "corrs_xy_test = np.zeros((10, K_FEAT))\n",
    "\n",
    "for i, (train_idx, test_idx) in enumerate(skf.split(X, y)):\n",
    "    X_train, y_train, c_train = X[train_idx], y[train_idx], c[train_idx]\n",
    "    X_test, y_test, c_test = X[test_idx], y[test_idx], c[test_idx]\n",
    "    \n",
    "    corrs_xy_train[i, :] = np.array([pearsonr(y_train, X_train[:, i])[0] for i in range(X.shape[1])])\n",
    "    corrs_xy_test[i, :] = np.array([pearsonr(y_test, X_test[:, i])[0] for i in range(X.shape[1])])\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    scores[i] = pipeline.score(X_test, y_test)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario 4: what happens if we vary the number of samples? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confound = categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_splits = 10\n",
    "permutations = 3\n",
    "\n",
    "pipeline = Pipeline([('scaler', StandardScaler()),\n",
    "                     ('clf', SVC(kernel='linear'))])\n",
    "\n",
    "data_args = dict(n_samp=None, k_feat=5, c_type='categorical', corr_cy=None,\n",
    "                 signal_r2=0.1, confound_r2=0.1, verbose=False)\n",
    "\n",
    "n_samples_vec = [20, 50, 100, 200, 500, 1000]\n",
    "\n",
    "baseline_scores = np.zeros((permutations, len(n_samples_vec)))\n",
    "\n",
    "results = []\n",
    "for perm in np.arange(permutations):\n",
    "\n",
    "    print(\"Permutation: %i\" % (perm + 1))\n",
    "    \n",
    "    Xbase, ybase = generate_data(**base_args) \n",
    "    baseline_scores[perm] = cross_val_score(pipeline, Xbase, ybase, cv=n_splits).mean()\n",
    "\n",
    "    for i, n_samp in enumerate(n_samples_vec):\n",
    "        data_args.update(n_samp=n_samp)\n",
    "        \n",
    "        base_args = deepcopy(data_args)\n",
    "        base_args['c_type'] = 'none'\n",
    "        Xbase, ybase = generate_data(**base_args) \n",
    "        baseline_scores[perm, i] = cross_val_score(pipeline, Xbase, ybase, cv=n_splits).mean()\n",
    "        \n",
    "        for corr_cy in [0.4, 0.5, 0.6, 0.7]:\n",
    "            data_args.update(corr_cy=corr_cy)\n",
    "            X, y, c = generate_data(**data_args)\n",
    "            results.append(run_without_confound_control(X, y, c, pipeline, n_splits, data_args))\n",
    "            results.append(run_with_confound_regression(X, y, c, pipeline, n_splits, data_args))\n",
    "            results.append(run_with_counterbalancing(X, y, c, pipeline, n_splits, data_args))\n",
    "            \n",
    "sns.set(font_scale=2)\n",
    "df = pd.concat(results)\n",
    "g = sns.factorplot(x='n_samp', y='score', hue='method', col='corr_cy', col_wrap=2,\n",
    "                   data=df, size=5, aspect=2, legend_out=False,\n",
    "                   palette=\"muted\", legend=True)\n",
    "g = g.map(plt.axhline, y=0.5, c='black', ls='--')\n",
    "g.set_axis_labels('N samples', 'Score')\n",
    "\n",
    "for ax in g.axes:\n",
    "    ax.plot(np.arange(len(n_samples_vec)), baseline_scores.mean(axis=0), color='red', ls='--')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confound = continuous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_splits = 10\n",
    "permutations = 2\n",
    "\n",
    "pipeline = Pipeline([('scaler', StandardScaler()),\n",
    "                     ('clf', SVC(kernel='linear'))])\n",
    "\n",
    "data_args = dict(n_samp=None, k_feat=5, c_type='continuous', corr_cy=None,\n",
    "                 signal_r2=0.1, confound_r2=0.1, verbose=False)\n",
    "\n",
    "n_samples_vec = [20, 50, 100, 200, 500, 1000]\n",
    "\n",
    "baseline_scores = np.zeros((permutations, len(n_samples_vec)))\n",
    "\n",
    "results = []\n",
    "for perm in np.arange(permutations):\n",
    "\n",
    "    print(\"Permutation: %i\" % (perm + 1))\n",
    "    \n",
    "    for i, n_samp in enumerate(n_samples_vec):\n",
    "        data_args.update(n_samp=n_samp)\n",
    "        \n",
    "        base_args = deepcopy(data_args)\n",
    "        base_args['c_type'] = 'none'\n",
    "        Xbase, ybase = generate_data(**base_args) \n",
    "        baseline_scores[perm, i] = cross_val_score(pipeline, Xbase, ybase, cv=n_splits).mean()\n",
    "        \n",
    "        for corr_cy in [0.4, 0.5, 0.6, 0.7]:\n",
    "            data_args.update(corr_cy=corr_cy)\n",
    "            X, y, c = generate_data(**data_args)\n",
    "            results.append(run_without_confound_control(X, y, c, pipeline, n_splits, data_args))\n",
    "            results.append(run_with_confound_regression(X, y, c, pipeline, n_splits, data_args))\n",
    "            results.append(run_with_counterbalancing(X, y, c, pipeline, n_splits, data_args,\n",
    "                                                     c_type='continuous', metric='corr', threshold=0.01))\n",
    "            \n",
    "sns.set(font_scale=2)\n",
    "df = pd.concat(results)\n",
    "g = sns.factorplot(x='n_samp', y='score', hue='method', col='corr_cy', col_wrap=2,\n",
    "                   data=df, size=5, aspect=2, legend_out=False,\n",
    "                   palette=\"muted\", legend=True)\n",
    "g = g.map(plt.axhline, y=0.5, c='black', ls='--')\n",
    "g.set_axis_labels('N samples', 'Score')\n",
    "for ax in g.axes:\n",
    "    ax.plot(np.arange(len(n_samples_vec)), baseline_scores.mean(axis=0), color='red', ls='--')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario 5: what happens when we vary the number of features?\n",
    "We also vary the strength of the confound signal in X (confound_r2)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confound = categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_splits = 10\n",
    "permutations = 1\n",
    "\n",
    "pipeline = Pipeline([('scaler', StandardScaler()),\n",
    "                     ('clf', SVC(kernel='linear'))])\n",
    "\n",
    "data_args = dict(n_samp=240, k_feat=None, c_type='categorical', corr_cy=0.7,\n",
    "                 signal_r2=0.1, confound_r2=None, verbose=False)\n",
    "\n",
    "k_feat_vec = [1, 5, 10, 20, 50, 100, 500, 1000, 10000]\n",
    "\n",
    "baseline_scores = np.zeros((permutations, len(k_feat_vec)))\n",
    "\n",
    "results = []\n",
    "for perm in np.arange(permutations):\n",
    "\n",
    "    print(\"Permutation: %i\" % (perm + 1))\n",
    "    \n",
    "    for i, k_feat in enumerate(k_feat_vec):\n",
    "        data_args.update(k_feat=k_feat)\n",
    "        print(\"k feat: %i\" % k_feat)\n",
    "        base_args = deepcopy(data_args)\n",
    "        base_args['c_type'] = 'none'\n",
    "        Xbase, ybase = generate_data(**base_args) \n",
    "        baseline_scores[perm, i] = cross_val_score(pipeline, Xbase, ybase, cv=n_splits).mean()\n",
    "        \n",
    "        for confound_r2 in [0, 0.1, 0.2, 0.3, 0.4]:\n",
    "            data_args.update(confound_r2=confound_r2)\n",
    "            X, y, c = generate_data(**data_args)\n",
    "            results.append(run_without_confound_control(X, y, c, pipeline, n_splits, data_args))\n",
    "            results.append(run_with_confound_regression(X, y, c, pipeline, n_splits, data_args))\n",
    "            results.append(run_with_counterbalancing(X, y, c, pipeline, n_splits, data_args,\n",
    "                                                     c_type='categorical'))\n",
    "\n",
    "sns.set(font_scale=2)\n",
    "df = pd.concat(results)\n",
    "g = sns.factorplot(x='k_feat', y='score', hue='method', col='confound_r2', col_wrap=2,\n",
    "                   data=df, size=5, aspect=2, legend_out=False,\n",
    "                   palette=\"muted\", legend=True)\n",
    "g = g.map(plt.axhline, y=0.5, c='black', ls='--')\n",
    "g.set_axis_labels('K features', 'Score')\n",
    "\n",
    "for ax in g.axes:\n",
    "    ax.plot(np.arange(len(k_feat_vec)), baseline_scores.mean(axis=0), color='red', ls='--')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confound = continuous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_splits = 10\n",
    "permutations = 1\n",
    "\n",
    "pipeline = Pipeline([('scaler', StandardScaler()),\n",
    "                     ('clf', SVC(kernel='linear'))])\n",
    "\n",
    "data_args = dict(n_samp=240, k_feat=None, c_type='continuous', corr_cy=0.7,\n",
    "                 signal_r2=0.1, confound_r2=None, verbose=False)\n",
    "\n",
    "k_feat_vec = [1, 5, 10, 20, 50, 100, 500, 1000, 10000]\n",
    "\n",
    "baseline_scores = np.zeros((permfor ax in g.axes:\n",
    "    ax.plot(np.arange(len(k_feat_vec)), baseline_scores.mean(axis=0), color='red', ls='--')utations, len(k_feat_vec)))\n",
    "\n",
    "results = []\n",
    "for perm in np.arange(permutations):\n",
    "\n",
    "    print(\"Permutation: %i\" % (perm + 1))\n",
    "    \n",
    "    for i, k_feat in enumerate(k_feat_vec):\n",
    "        data_args.update(k_feat=k_feat)\n",
    "        print(\"k feat: %i\" % k_feat)\n",
    "        base_args = deepcopy(data_args)\n",
    "        base_args['c_type'] = 'none'\n",
    "        Xbase, ybase = generate_data(**base_args) \n",
    "        baseline_scores[perm, i] = cross_val_score(pipeline, Xbase, ybase, cv=n_splits).mean()\n",
    "        \n",
    "        for confound_r2 in [0, 0.1, 0.2, 0.3, 0.4]:\n",
    "            data_args.update(confound_r2=confound_r2)\n",
    "            X, y, c = generate_data(**data_args)\n",
    "            results.append(run_without_confound_control(X, y, c, pipeline, n_splits, data_args))\n",
    "            results.append(run_with_confound_regression(X, y, c, pipeline, n_splits, data_args))\n",
    "            results.append(run_with_counterbalancing(X, y, c, pipeline, n_splits, data_args,\n",
    "                                                     c_type='continuous', metric='corr', threshold=0.01))\n",
    "\n",
    "\n",
    "sns.set(font_scale=2)\n",
    "df = pd.concat(results)\n",
    "g = sns.factorplot(x='k_feat', y='score', hue='method', col='confound_r2', col_wrap=2,\n",
    "                   data=df, size=5, aspect=2, legend_out=False,\n",
    "                   palette=\"muted\", legend=True)\n",
    "g = g.map(plt.axhline, y=0.5, c='black', ls='--')\n",
    "g.set_axis_labels('K features', 'Score')\n",
    "for ax in g.axes:\n",
    "    ax.plot(np.arange(len(k_feat_vec)), baseline_scores.mean(axis=0), color='red', ls='--')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Messing around"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_splits = 10\n",
    "X, y, c = generate_data(n_samp=240, k_feat=5, c_type='categorical', corr_cy=0.6,\n",
    "                        signal_r2=0.1, confound_r2=0.2, verbose=False)\n",
    "\n",
    "skf = CounterbalancedStratifiedSplit(X, y, c, n_splits=n_splits, c_type='categorical', verbose=True)\n",
    "skf.check_counterbalance_and_subsample()\n",
    "\n",
    "X, y, c = X[skf.subsample_idx], y[skf.subsample_idx], c[skf.subsample_idx]    \n",
    "\n",
    "scores = np.zeros(n_splits)\n",
    "y_c_r2 = np.zeros(n_splits)\n",
    "y_xc_r2 = np.zeros((n_splits, X.shape[1]))\n",
    "y_x_r2 = np.zeros((n_splits, X.shape[1]))\n",
    "unique_var_x = np.zeros((n_splits, X.shape[1]))\n",
    "unique_var_c = np.zeros((n_splits, X.shape[1]))\n",
    "shared_var_xc = np.zeros((n_splits, X.shape[1]))\n",
    "d = np.zeros((n_splits, X.shape[1]))\n",
    "\n",
    "this_pipe = pipeline\n",
    "\n",
    "for i, (train_idx, test_idx) in enumerate(skf.split(X, y)):\n",
    "    X_train, y_train = X[train_idx], y[train_idx]\n",
    "    X_test, y_test = X[test_idx], y[test_idx]\n",
    "    c_train = c[train_idx][:, np.newaxis]\n",
    "    y_c_r2[i] = get_r2(c_train, y_train)\n",
    "    \n",
    "    for ii in range(X_train.shape[1]):\n",
    "        y_xc_r2[i, ii] = get_r2(np.hstack((X_train[:, ii][:, np.newaxis], c_train)), y_train)\n",
    "        y_x_r2[i, ii] = get_r2(X_train[:, ii], y_train)\n",
    "        \n",
    "        resid_y = 1 - y_xc_r2[i, ii]  # A = 1 - (B + C + D)\n",
    "        unique_var_x[i, ii] = y_xc_r2[i, ii] - y_c_r2[i]  # B\n",
    "        unique_var_c[i, ii] = y_xc_r2[i, ii] - y_x_r2[i, ii]  # D\n",
    "        shared_var_xc[i, ii] = 1 - resid_y - unique_var_x[i, ii] - unique_var_c[i, ii]  # C = \n",
    "        d[i, ii] = y_c_r2[i] - shared_var_xc[i, ii]\n",
    "    \n",
    "    print(\"TRAIN\")\n",
    "    print(\"R2(y_xc)): %r\" % np.round(y_xc_r2.mean(axis=0), 4).tolist())\n",
    "    print(\"R2(y_x): %r\" % np.round(y_x_r2.mean(axis=0), 4).tolist())\n",
    "    print(\"R2(signal): %r\" % np.round(unique_var_x.mean(axis=0), 4).tolist())\n",
    "    print(\"R2(confound): %r\" % np.round(shared_var_xc.mean(axis=0), 4).tolist())\n",
    "    print(\"R2(D): %r\" % np.round(d.mean(axis=0), 4).tolist())\n",
    "    \n",
    "    print('')\n",
    "\n",
    "    c_test = c[test_idx][:, np.newaxis]\n",
    "    for ii in range(X_test.shape[1]):\n",
    "        y_xc_r2[i, ii] = get_r2(np.hstack((X_test[:, ii][:, np.newaxis], c_test)), y_test)\n",
    "        y_x_r2[i, ii] = get_r2(X_test[:, ii], y_test)\n",
    "        \n",
    "        resid_y = 1 - y_xc_r2[i, ii]  # A = 1 - (B + C + D)\n",
    "        unique_var_x[i, ii] = y_xc_r2[i, ii] - y_c_r2[i]  # B\n",
    "        unique_var_c[i, ii] = y_xc_r2[i, ii] - y_x_r2[i, ii]  # D\n",
    "        shared_var_xc[i, ii] = 1 - resid_y - unique_var_x[i, ii] - unique_var_c[i, ii]  # C = \n",
    "        d[i, ii] = y_c_r2[i] - shared_var_xc[i, ii]\n",
    "    \n",
    "    print(\"TEST\")\n",
    "    print(\"R2(y_xc)): %r\" % np.round(y_xc_r2.mean(axis=0), 4).tolist())\n",
    "    print(\"R2(y_x): %r\" % np.round(y_x_r2.mean(axis=0), 4).tolist())\n",
    "    print(\"R2(signal): %r\" % np.round(unique_var_x.mean(axis=0), 4).tolist())\n",
    "    print(\"R2(confound): %r\" % np.round(shared_var_xc.mean(axis=0), 4).tolist())\n",
    "    print(\"R2(D): %r\" % np.round(d.mean(axis=0), 4).tolist())\n",
    "    \n",
    "    print('')\n",
    "\n",
    "    \n",
    "    this_pipe.fit(X_train, y_train)\n",
    "    scores[i] = this_pipe.score(X_test, y_test)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_splits = 10\n",
    "X, y, c = generate_data(n_samp=240, k_feat=5, c_type='categorical', corr_cy=0.4,\n",
    "                        signal_r2=0.1, confound_r2=0.1, verbose=False)\n",
    "\n",
    "scores = np.zeros(n_splits)\n",
    "y_c_r2 = np.zeros(n_splits)\n",
    "y_xc_r2 = np.zeros((n_splits, X.shape[1]))\n",
    "y_x_r2 = np.zeros((n_splits, X.shape[1]))\n",
    "unique_var_x = np.zeros((n_splits, X.shape[1]))\n",
    "unique_var_c = np.zeros((n_splits, X.shape[1]))\n",
    "shared_var_xc = np.zeros((n_splits, X.shape[1]))\n",
    "\n",
    "skf = StratifiedKFold(n_splits=n_splits)\n",
    "this_pipe = Pipeline(pipeline)\n",
    "for i, (train_idx, test_idx) in enumerate(skf.split(X, y)):\n",
    "    cr = ConfoundRegressor(confound=c, fit_idx=train_idx, cross_validate=True)\n",
    "    X_train, y_train = X[train_idx], y[train_idx]\n",
    "    X_test, y_test = X[test_idx], y[test_idx]\n",
    "\n",
    "    c_train = c[train_idx][:, np.newaxis]\n",
    "    y_c_r2[i] = get_r2(c_train, y_train)\n",
    "\n",
    "    X_train = cr.fit_transform(X_train)\n",
    "    X_test = cr.transform(X_test)\n",
    "    \n",
    "    for ii in range(X_train.shape[1]):\n",
    "        y_xc_r2[i, ii] = get_r2(np.hstack((X_train[:, ii][:, np.newaxis], c_train)), y_train)\n",
    "        y_x_r2[i, ii] = get_r2(X_train[:, ii], y_train)\n",
    "        \n",
    "        resid_y = 1 - y_xc_r2[i, ii]  # A = 1 - (B + C + D)\n",
    "        unique_var_x[i, ii] = y_xc_r2[i, ii] - y_c_r2[i]  # B\n",
    "        unique_var_c[i, ii] = y_xc_r2[i, ii] - y_x_r2[i, ii]  # D\n",
    "        shared_var_xc[i, ii] = 1 - resid_y - unique_var_x[i, ii] - unique_var_c[i, ii]  # C = \n",
    "    \n",
    "    print(\"R2(y_xc)): %r\" % np.round(y_xc_r2.mean(axis=0), 4).tolist())\n",
    "    print(\"R2(y_x): %r\" % np.round(y_x_r2.mean(axis=0), 4).tolist())\n",
    "    print(\"R2(signal): %r\" % np.round(unique_var_x.mean(axis=0), 4).tolist())\n",
    "    print(\"R2(confound): %r\" % np.round(shared_var_xc.mean(axis=0), 4).tolist())\n",
    "    \n",
    "    print('')\n",
    "    \n",
    "    this_pipe.fit(X_train, y_train)\n",
    "    scores[i] = this_pipe.score(X_test, y_test)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An old version of the data generation algorithm\n",
    "Didn't really work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_data_from_dist(n_samp, k_feat, c_type, corr_cy, signal_r2, confound_r2=None, verbose=False, plot=False):\n",
    "    \"\"\" Similar to above, but draw generative parameters from distribution. \"\"\"\n",
    "    \n",
    "    if n_samp % 2 != 0:\n",
    "        raise ValueError(\"Please select an even number of samples \"\n",
    "                         \"(Makes things easier.)\")\n",
    "\n",
    "    if confound_r2 is not None:\n",
    "        if np.abs(corr_cy) < np.sqrt(confound_r2):\n",
    "            raise ValueError(\"The desired corr_cy value is less than the square \"\n",
    "                             \"root of the desired confound R-squared ... This is \"\n",
    "                             \"impossible to generate.\")\n",
    "        \n",
    "    # Generate y (balanced, 50% class 0, 50% class 1)\n",
    "    y = np.repeat([0, 1], repeats=n_samp / 2)\n",
    "    \n",
    "    # Generate c (confound), with given correlation corr_cy\n",
    "    if c_type == 'categorical':\n",
    "        # Simply shift (\"roll\") y to create correlation using the \"formula\":\n",
    "        # to-shift = N / 4 * (1 - corr_cy)\n",
    "        to_roll = int((n_samp / 4) * (1 - corr_cy))\n",
    "        c = np.roll(y, to_roll)\n",
    "    elif c_type == 'continuous':\n",
    "        # If c is continuous, just sample y + random noise\n",
    "        noise_factor = 100\n",
    "        c = y + np.random.randn(n_samp) * noise_factor\n",
    "        corr = pearsonr(c, y)[0]\n",
    "        \n",
    "        while np.abs(corr - corr_cy) > 0.01:\n",
    "            # Decrease noise if the difference is too big\n",
    "            noise_factor -= 0.01\n",
    "            c = y + np.random.randn(n_samp) * noise_factor\n",
    "            corr = pearsonr(c, y)[0]        \n",
    "    else:\n",
    "        raise ValueError(\"For c_type, please select from {'continuous', \"\n",
    "                         \"'categorical'}\")\n",
    "\n",
    "    noise_factor = 0.1\n",
    "\n",
    "    while True:\n",
    "        \n",
    "        gen_y_mean = np.random.normal(0, 1, size=1)\n",
    "        gen_c_mean = np.random.normal(0, 1, size=1)\n",
    "        gen_y_std = 0.5#np.abs(np.random.normal(0.0, 0.1, size=1))\n",
    "        gen_c_std = 0.5#np.abs(np.random.normal(0.0, 0.1, size=1))\n",
    "        \n",
    "        should_continue = False\n",
    "        gen_beta_y = np.random.normal(gen_y_mean, gen_y_std, size=(n_samp, k_feat))\n",
    "        gen_beta_c = np.random.normal(gen_c_mean, gen_c_std, size=(n_samp, k_feat))\n",
    "\n",
    "        X = (gen_beta_y * y[:, np.newaxis] + \n",
    "             gen_beta_c * c[:, np.newaxis] + \n",
    "             np.random.randn(n_samp, k_feat) * noise_factor)\n",
    "        \n",
    "        y_x_r2 = np.array([get_r2(iv=X[:, i, np.newaxis], dv=y) for i in range(k_feat)])  # B + C\n",
    "        \n",
    "        if confound_r2 is None:\n",
    "            # We don't care about confound_r2\n",
    "            unique_var_x = y_x_r2\n",
    "        else:\n",
    "            # Fit y = b1X + b2C\n",
    "            y_xc_r2 = np.array([get_r2(iv=np.hstack((X[:, i, np.newaxis], c[:, np.newaxis])), dv=y)\n",
    "                                for i in range(k_feat)])  # B + C + D\n",
    "            resid_y = 1 - y_xc_r2  # A = 1 - (B + C + D)\n",
    "\n",
    "            # Fit y = b1C\n",
    "            y_c_r2 = get_r2(iv=c, dv=y)  # C + D\n",
    "            unique_var_x = y_xc_r2 - y_c_r2  # B\n",
    "\n",
    "        # Increase/decrease generative param for y if difference \n",
    "        # r(yx.c) is too small/big ...\n",
    "        difference_obs_vs_desired = unique_var_x.mean() - signal_r2\n",
    "        if np.abs(difference_obs_vs_desired) > 0.01:\n",
    "            if difference_obs_vs_desired < 0:\n",
    "                gen_y_mean += 0.01\n",
    "            else:\n",
    "                gen_y_mean -= 0.01\n",
    "\n",
    "            if confound_r2 is None:\n",
    "                continue\n",
    "            else:\n",
    "                should_continue = True\n",
    "        else:\n",
    "            if confound_r2 is None:\n",
    "                break\n",
    "  \n",
    "        unique_var_c = y_xc_r2 - y_x_r2  # D\n",
    "        shared_var_xc = 1 - resid_y - unique_var_x - unique_var_c  # C\n",
    "\n",
    "        # Also check if shared variance of c and x (component C) is appropriate;\n",
    "        # if not, adjust generative parameter and CONTINUE\n",
    "        difference_obs_vs_desired = shared_var_xc.mean() - confound_r2\n",
    "        if np.abs(difference_obs_vs_desired) > 0.01:\n",
    "            if difference_obs_vs_desired < 0:\n",
    "                gen_c_mean += 0.05\n",
    "            else:\n",
    "                gen_c_mean -= 0.05\n",
    "            should_continue = True\n",
    "\n",
    "        if should_continue:\n",
    "            \n",
    "            if verbose:\n",
    "                print(\"Total r2: %.3f\" % y_x_r2.mean())\n",
    "                print(\"Confound r2: %.3f\" % shared_var_xc.mean())\n",
    "                print(\"Signal r2: %.3f\" % unique_var_x.mean())\n",
    "                print(\"gen_y_mean: %.2f\" % gen_y_mean)\n",
    "                print(\"gen_c_mean: %.2f\" % gen_c_mean, end='\\n\\n')\n",
    "            continue\n",
    "\n",
    "        # If we didn't encounter a \"break\" statement, we must have found\n",
    "        # data with the correct specifications ...\n",
    "        signal_r2_values = unique_var_x\n",
    "        if confound_r2 is not None:\n",
    "            confound_r2_values = shared_var_xc\n",
    "        break\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Signal r2: %.3f\" % signal_r2_values.mean())\n",
    "        \n",
    "        if confound_r2 is not None:\n",
    "            print(\"Confound r2: %.3f\" % confound_r2_values.mean())\n",
    "        \n",
    "        print(\"Final gen_y_mean: %.3f\" % gen_y_mean)\n",
    "        print(\"Final gen_c_mean: %.3f\" % gen_c_mean)\n",
    "    \n",
    "    if plot:\n",
    "        kinds = ['signal_r2'] * k_feat + ['confound_r2'] * k_feat\n",
    "        df = dict(corrs=np.hstack((signal_r2_values, confound_r2_values)), kind=kinds)\n",
    "        g = sns.FacetGrid(pd.DataFrame(df), col=\"kind\", margin_titles=True)\n",
    "        g.map(plt.hist, \"corrs\", color=\"steelblue\")\n",
    "        \n",
    "    if confound_r2 is None:\n",
    "        return X, y\n",
    "    else:\n",
    "        return X, y, c"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
