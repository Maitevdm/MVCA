{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confounds in fMRI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from nistats.hemodynamic_models import spm_hrf\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from scipy.stats import pearsonr\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.4681698445780382\n"
     ]
    }
   ],
   "source": [
    "class FmriData:\n",
    "    \"\"\" Generates fMRI data.\n",
    "     \n",
    "    Parameters\n",
    "    ----------\n",
    "    P : int\n",
    "        Number of conditions\n",
    "    I : int\n",
    "        Number of instances per condition\n",
    "    I_dur : int\n",
    "        Duration of trial in seconds\n",
    "    ISIs = list\n",
    "        List of possible ISIs\n",
    "    TR : int\n",
    "        Time to repetition (must be int for simplicity)\n",
    "    K : tuple\n",
    "        Voxel dimensions\n",
    "    ar_rho1 : float\n",
    "        AR(p)Â correlation.\n",
    "    smoothness : int\n",
    "        Smoothing factor (in sigma)\n",
    "    \"\"\"\n",
    " \n",
    "    def __init__(self, P=2, I=20, I_dur=2, ISIs=(4, 5, 6, 7), TR=2, K=(3, 3),\n",
    "                 ar1_rho=0.5, smoothness=2, noise_factor=1, cond_means=None, cond_stds=None,\n",
    "                 confound_corr=None, confound_mod='additive'):\n",
    "        \"\"\" Initializes FmriData object. \"\"\"\n",
    "        self.P = P\n",
    "        self.I = I\n",
    "        self.I_dur = I_dur\n",
    "        self.ISIs = ISIs\n",
    "        self.TR = TR\n",
    "        self.K = K\n",
    "        self.ar1_rho = ar1_rho\n",
    "        self.smoothness=smoothness\n",
    "        self.noise_factor = noise_factor\n",
    "        self.cond_means = cond_means\n",
    "        self.cond_stds = cond_stds\n",
    "        self.confound_corr = confound_corr\n",
    "        self.confound_mod = 'additive'\n",
    "        \n",
    "        self.X = None\n",
    "        self.y = None\n",
    "        self.conds = None\n",
    "        self.conf = None\n",
    "        self.conf_conv = None\n",
    "        self.V = None\n",
    "        self.hrf = None\n",
    "    \n",
    "    def generate_data(self, X=None, single_trial=True):\n",
    "        \"\"\" Generates fMRI data (X, y) with or without confound. \"\"\"\n",
    "\n",
    "        if X is None:\n",
    "            X, conds = self._generate_X(single_trial=single_trial)\n",
    "        \n",
    "        y, true_betas = self._generate_y(X, conds)\n",
    "        self.true_betas = true_betas\n",
    "        return X, y, conds\n",
    "\n",
    "    def _generate_confound(self, confound_corr, confound_mod, conds):\n",
    "        \"\"\" Generates a confound with specified correlation to trials. \"\"\"\n",
    "        \n",
    "        i = 0\n",
    "        weight = 0.0001\n",
    "        conf = np.random.normal(0, 1, conds.size) + (conds - conds.mean()) * weight\n",
    "        this_corr = pearsonr(conf, conds)[0]\n",
    "        diff = confound_corr - this_corr \n",
    "        while np.abs(diff) > 0.01:\n",
    "            if diff > 0:\n",
    "                weight += 0.0001\n",
    "            else:\n",
    "                weight -= 0.0001\n",
    "            conf = np.random.normal(0, 1, conds.size) + conds * weight\n",
    "            this_corr = pearsonr(conf, conds)[0]\n",
    "            diff = confound_corr - this_corr \n",
    "            i += 1\n",
    "            \n",
    "            if i > 100000:\n",
    "                raise ValueError(\"Could not create confound with correlation %.3f\" % confound_corr)\n",
    "        \n",
    "        return conf\n",
    "                \n",
    "    def _generate_X(self, single_trial=True):\n",
    "        \"\"\" Generates X (design matrix). \"\"\"\n",
    "        \n",
    "        confound_corr, confound_mod = self.confound_corr, self.confound_mod\n",
    "        \n",
    "        # Generate I trials for P conditions\n",
    "        conds = np.repeat(np.arange(self.P), self.I)\n",
    "        conds = np.random.permutation(conds)  # shuffle trials\n",
    "        self.conds = conds\n",
    "\n",
    "        if confound_corr is not None:\n",
    "            conf = self._generate_confound(confound_corr, confound_mod, conds)\n",
    "            self.conf = conf\n",
    "        else:\n",
    "            conf = None\n",
    "\n",
    "        if len(conds) % len(self.ISIs) != 0:\n",
    "            raise ValueError(\"Please choose ISIs which can spread across trials evenly.\")\n",
    "\n",
    "        ISIs = np.repeat(self.ISIs, len(conds) / len(self.ISIs))\n",
    "        ISIs = np.random.permutation(ISIs)\n",
    "        run_dur = (np.sum(ISIs) + self.I_dur * len(conds))  # run-duration\n",
    "        \n",
    "        osf = 10  # oversampling factor for onsets/hrf\n",
    "        if single_trial:  # nr of regressors = conditions * trials\n",
    "            X = np.zeros((run_dur * osf, self.P*self.I))\n",
    "        else:  # nr regressors = nr conditions\n",
    "            X = np.zeros((run_dur * osf, self.P))\n",
    "\n",
    "        current_onset = 0  # start creating onsets\n",
    "        for i, trial in enumerate(conds):\n",
    "\n",
    "            if single_trial:\n",
    "                \n",
    "                if conf is not None and confound_mod == 'modulation':\n",
    "                    X[current_onset:(current_onset + self.I_dur * osf + conf[i] * osf), i] = 1\n",
    "                else:\n",
    "                    X[current_onset:(current_onset + self.I_dur * osf), i] = 1\n",
    "            else:\n",
    "                X[current_onset:(current_onset + self.I_dur * osf), trial] = 1\n",
    "\n",
    "            this_ITI = self.I_dur * osf + ISIs[i] * osf\n",
    "            current_onset += this_ITI\n",
    "    \n",
    "        # Define HRF\n",
    "        if self.hrf is None:\n",
    "            hrf = spm_hrf(tr=self.TR, oversampling=self.TR*osf,\n",
    "                          time_length=32.0, onset=0.0)\n",
    "            hrf = hrf / np.max(hrf)  # scale HRF, peak = 1\n",
    "        else:\n",
    "            hrf = self.hrf\n",
    "\n",
    "        if conf is not None and confound_mod == 'additive':\n",
    "            conf_pred = np.zeros(run_dur * osf)\n",
    "            conf_pred[X.sum(axis=1) != 0] = np.repeat(conf, repeats=osf)\n",
    "            X = np.c_[X, conf_pred]\n",
    "\n",
    "        # Convolve regressors with HRF\n",
    "        X = np.hstack([np.convolve(X[:, i], hrf)[:run_dur*osf, np.newaxis]\n",
    "                       for i in range(X.shape[1])])\n",
    "        \n",
    "        X = X[::self.TR*osf, :]  # downsample\n",
    "        X = np.c_[np.ones(X.shape[0]), X]  # stack intercept\n",
    "        if conf is not None and confound_mod == 'additive':\n",
    "            conf_conv = X[:, -1]\n",
    "            self.conf_conv = conf_conv\n",
    "            X = X[:, :-1]\n",
    "            \n",
    "        return X, conds\n",
    "\n",
    "    def _generate_y(self, X, conds, confound_corr=None, confound_mod='additive', single_trial=True):\n",
    "        \"\"\" Generate signals (y). \"\"\"\n",
    "        \n",
    "        confound_corr, confound_mod = self.confound_corr, self.confound_mod\n",
    "        \n",
    "        N = X.shape[0]  # N = (downsampled) timepoints\n",
    "    \n",
    "        # Create ar1 covariance matrix and generate noise\n",
    "        if self.V is None:\n",
    "            self.V = self._generate_V(N)\n",
    "\n",
    "        noise = np.random.multivariate_normal(np.zeros(N),\n",
    "                                              self.V,\n",
    "                                              size=np.prod(K)).T\n",
    "        # Create condition means/stds\n",
    "        if single_trial:\n",
    "            cond_means = np.array([self.cond_means[i] for i in conds])\n",
    "            cond_stds = np.array([self.cond_stds[i] for i in conds])\n",
    "            \n",
    "            if confound_mod == 'additive' and confound_corr is not None:\n",
    "                cond_means = cond_means.astype(float) + self.conf\n",
    "        else:\n",
    "            cond_means = self.cond_means\n",
    "            cond_stds = self.cond_stds\n",
    "        \n",
    "        # Add intercept effects\n",
    "        cond_means = np.append(0, cond_means)\n",
    "        cond_stds = np.append(1, cond_stds)\n",
    "\n",
    "        # Create true paramaters\n",
    "        if single_trial: \n",
    "            covtmp = np.eye(P*I + 1)\n",
    "            covtmp *= cond_stds\n",
    "            true_betas = np.random.multivariate_normal(cond_means, covtmp, size=np.prod(K)).T\n",
    "        else:\n",
    "            covtmp = np.eye(P + 1)\n",
    "            covtmp *= cond_stds\n",
    "            true_betas = np.random.multivariate_normal(cond_means, covtmp, size=np.prod(K)).T\n",
    "\n",
    "        # Create signal!\n",
    "        y = X.dot(true_betas) + noise\n",
    "        if self.smoothness is not None:\n",
    "            y = gaussian_filter(y.reshape((N,) + K), 1).reshape(N, np.prod(K))\n",
    "        \n",
    "        return y, true_betas\n",
    "        \n",
    "    def fit_glm(self, X, y, control_for_conf=False, remove_icept=True):\n",
    "        \"\"\" Fits a GLM (using generalized least squares).\"\"\"\n",
    "        \n",
    "        if control_for_conf:\n",
    "            conf = self.conf_conv\n",
    "            X = np.c_[X, conf]\n",
    "        \n",
    "        est_betas = np.zeros((X.shape[1], y.shape[1]))\n",
    "        stderrs = np.zeros_like(est_betas)\n",
    "        tvals = np.zeros_like(est_betas)\n",
    "        \n",
    "        for i in range(y.shape[1]):\n",
    "            \n",
    "            gls_results = sm.GLS(y[:, i], X, sigma=self.V).fit()\n",
    "            est_betas[:, i] = gls_results.params\n",
    "            stderrs[:, i] = gls_results.bse\n",
    "            tvals[:, i] = gls_results.tvalues\n",
    "\n",
    "        if control_for_conf:\n",
    "            est_betas = est_betas[:-1, :]\n",
    "            stderrs = stderrs[:-1, :]\n",
    "            tvals = tvals[:-1, :]\n",
    "\n",
    "        if remove_icept:\n",
    "            est_betas = est_betas[1:, :]\n",
    "            stderrs = stderrs[1:, :]\n",
    "            tvals = tvals[1:, :]\n",
    "        \n",
    "        return est_betas, stderrs, tvals\n",
    "\n",
    "    def _generate_V(self, N):\n",
    "        \"\"\" Generates a autocovariance matrix based on a AR(1) model. \"\"\"\n",
    "        rho = self.ar1_rho\n",
    "        cov = rho ** scipy.linalg.toeplitz(np.arange(N))\n",
    "        return cov * self.noise_factor\n",
    "\n",
    "    def plot(self, X, y, conds, voxel=(0, 0)):\n",
    "        \"\"\" Plots the design and signal of a particular voxel from a particular run. \"\"\"\n",
    "        fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(20, 5), sharex=True)\n",
    "        #X, y, conds = self.X, self.y, self.conds\n",
    "        \n",
    "        ax[0].set_prop_cycle('color', [plt.cm.Dark2(i) for i in conds])\n",
    "        ax[0].plot(X[:, 1:])\n",
    "        ax[0].axhline(0, ls='--', c='k', lw=1)\n",
    "        ax[0].set_xlim(0, X.shape[0])\n",
    "        ax[0].set_xlabel('Time (in dynamics)', fontsize=15)\n",
    "        ax[0].set_ylabel('Amplitude (a.u.)', fontsize=15)\n",
    "\n",
    "        yresh = y.reshape((y.shape[0],) + self.K)\n",
    "        ax[1].plot(yresh[:, voxel[0], voxel[1]])\n",
    "        ax[1].axhline(0, ls='--', c='k', lw=1)\n",
    "        ax[1].set_xlabel('Time (in dynamics)', fontsize=15)\n",
    "        \n",
    "        sns.despine()\n",
    "        fig.tight_layout()\n",
    "        fig.show()\n",
    "        \n",
    "P = 2  # conditions\n",
    "I = 40  # trials\n",
    "I_dur = 1  # trial-duration in seconds\n",
    "ISIs = [14, 16]\n",
    "TR = 2  # in seconds\n",
    "K = (10, 10)  # voxels\n",
    "ar1_rho = 0.5  # autocorr\n",
    "smoothness = 1  # spatial smoothness in sigma\n",
    "noise_factor = 0.1  # scaling for V\n",
    "cond_means = (0, 0)\n",
    "cond_stds = (0.1, 0.1)\n",
    "\n",
    "fmri_gen = FmriData(P=P, I=I, I_dur=I_dur, ISIs=ISIs, TR=TR,\n",
    "                    K=K, ar1_rho=ar1_rho, smoothness=smoothness,\n",
    "                    noise_factor=noise_factor, cond_means=cond_means,\n",
    "                    cond_stds=cond_stds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check: how does it do with null-data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa17bb33dadc44a8b5c61562393defa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "iters = 10\n",
    "mean_acc = np.zeros(iters)\n",
    "mean_acc2 = np.zeros(iters)\n",
    "mean_acc3 = np.zeros(iters)\n",
    "mean_acc4 = np.zeros(iters)\n",
    "\n",
    "pipe = make_pipeline(StandardScaler(), SVC(kernel='linear'))\n",
    "\n",
    "for i in tqdm_notebook(range(iters)):\n",
    "    \n",
    "    X, y, conds = fmri_gen.generate_data(confound_corr=0.8)\n",
    "    b, v, t = fmri_gen.fit_glm(X, y, control_for_conf=False)\n",
    "    mean_acc[i] = cross_val_score(pipe, b, conds, cv=10).mean()\n",
    "    b, v, t = fmri_gen.fit_glm(X, y, control_for_conf=True)\n",
    "    mean_acc2[i] = cross_val_score(pipe, b, conds, cv=10).mean()\n",
    "    mean_acc3[i] = cross_val_score(pipe, t, conds, cv=10).mean()\n",
    "    mean_acc4[i] = cross_val_score(pipe, v, conds, cv=10).mean()\n",
    "\n",
    "print(mean_acc.mean())\n",
    "print(mean_acc2.mean())\n",
    "print(mean_acc3.mean())\n",
    "print(mean_acc4.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the 'additive' method (Woolgar et al., 2014)\n",
    "Seems to work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100  # timepoints\n",
    "\n",
    "onsets_A = np.arange(0, N, 10)\n",
    "X_gen = np.zeros(N)\n",
    "X_gen[onsets] = 1\n",
    "conf = np.random.normal(0, 1, onsets.size)\n",
    "X_gen[onsets] += conf\n",
    "hrf = spm_hrf(3, oversampling=1)\n",
    "X_gen = np.convolve(X_gen, hrf)[:X_gen.shape[0]]\n",
    "true_beta = 1\n",
    "y_gen = X_gen*true_beta\n",
    "\n",
    "X_add = np.zeros(N)\n",
    "X_add[onsets] = 1\n",
    "X_add = np.convolve(X_add, hrf)[:X_add.shape[0]]\n",
    "\n",
    "conf_pred = np.zeros(N)\n",
    "conf_pred[onsets] = conf\n",
    "conf_conv = np.convolve(conf_pred, hrf)[:conf_pred.shape[0]]\n",
    "X_add = np.c_[X_add, conf_conv]\n",
    "y_add = X_add.dot(np.array([1, 1])[:, np.newaxis])\n",
    "\n",
    "plt.plot(y_gen)\n",
    "plt.plot(y_add)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100  # timepoints\n",
    "\n",
    "onsets_A = np.arange(0, N, 20)\n",
    "onsets_B = np.arange(10, N, 20)\n",
    "X_gen = np.zeros((N, 2))\n",
    "X_gen[onsets_A, 0] = 1\n",
    "X_gen[onsets_B, 1] = 1\n",
    "\n",
    "conds = np.tile([0, 1], 5)\n",
    "conf = np.random.normal(0, 1, 10) + conds\n",
    "X_gen[onsets_A, 0] += conf[::2]\n",
    "X_gen[onsets_B, 1] += conf[1::2]\n",
    "\n",
    "hrf = spm_hrf(3, oversampling=1)\n",
    "X_gen = np.hstack([np.convolve(X_gen[:, i], hrf)[:X_gen.shape[0], np.newaxis] for i in range(2)])\n",
    "plt.plot(X_gen)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
